{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c2e6453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from typing import List, Tuple\n",
    "import os\n",
    "import joblib\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a9e803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading processed data...\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "print(\"üìÇ Loading processed data...\")\n",
    "train_df = pd.read_pickle('../data/processed/train.pkl')\n",
    "test_df = pd.read_pickle('../data/processed/test.pkl')\n",
    "\n",
    "# Variants\n",
    "variants = [\n",
    "    'without_lemma',\n",
    "    'with_lemma',\n",
    "    'with_lemma_pos',\n",
    "    'with_dep_tree',\n",
    "    'with_chunking'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3323fce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare text from tokens/ngrams\n",
    "def prepare_text(tokens: List, ngrams_b: List[Tuple], ngrams_t: List[Tuple], use_ngrams: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Convert tokens and optionally ngrams to string for TF-IDF.\n",
    "    For ngrams, join tuples into space-separated strings.\n",
    "    \"\"\"\n",
    "    if not tokens:\n",
    "        return ''\n",
    "    # Handle different token formats (str or tuples)\n",
    "    if isinstance(tokens[0], str):\n",
    "        text = ' '.join(tokens)\n",
    "    elif isinstance(tokens[0], tuple):\n",
    "        text = ' '.join(['_'.join(t) for t in tokens])\n",
    "    else:\n",
    "        text = ''\n",
    "    \n",
    "    if use_ngrams:\n",
    "        bigrams_str = ' '.join(['_'.join(gram) for gram in ngrams_b]) if ngrams_b else ''\n",
    "        trigrams_str = ' '.join(['_'.join(gram) for gram in ngrams_t]) if ngrams_t else ''\n",
    "        text = f\"{text} {bigrams_str} {trigrams_str}\".strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8702758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results storage\n",
    "results_multi = {}\n",
    "results_binary = {dim: {} for dim in ['IE', 'NS', 'FT', 'JP']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e924932f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Processing variant: without_lemma\n",
      "üìù Preparing text features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6940/6940 [00:01<00:00, 3574.41it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1735/1735 [00:00<00:00, 4061.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Training multi-class model with balanced class weights...\n",
      "Multi-class - Accuracy: 0.3476, F1: 0.3511\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.24      0.29      0.26        38\n",
      "        ENFP       0.29      0.32      0.30       135\n",
      "        ENTJ       0.09      0.15      0.12        46\n",
      "        ENTP       0.32      0.39      0.35       137\n",
      "        ESFJ       0.00      0.00      0.00         9\n",
      "        ESFP       0.00      0.00      0.00        10\n",
      "        ESTJ       0.00      0.00      0.00         8\n",
      "        ESTP       0.00      0.00      0.00        18\n",
      "        INFJ       0.41      0.34      0.37       294\n",
      "        INFP       0.50      0.44      0.47       366\n",
      "        INTJ       0.35      0.33      0.34       218\n",
      "        INTP       0.44      0.46      0.45       261\n",
      "        ISFJ       0.07      0.09      0.08        33\n",
      "        ISFP       0.13      0.15      0.14        54\n",
      "        ISTJ       0.09      0.07      0.08        41\n",
      "        ISTP       0.27      0.36      0.31        67\n",
      "\n",
      "    accuracy                           0.35      1735\n",
      "   macro avg       0.20      0.21      0.20      1735\n",
      "weighted avg       0.36      0.35      0.35      1735\n",
      "\n",
      "üß† Training binary model for IE with balanced class weights...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Loop over variants\n",
    "for var in variants:\n",
    "    print(f\"\\nüîç Processing variant: {var}\")\n",
    "    \n",
    "    # Prepare train and test texts\n",
    "    print(\"üìù Preparing text features...\")\n",
    "    tqdm.pandas()\n",
    "    train_df['text'] = train_df.progress_apply(\n",
    "        lambda row: prepare_text(row[f'tokens_{var}'], row[f'Bigrams_{var}'], row[f'Trigrams_{var}'], use_ngrams=True), axis=1\n",
    "    )\n",
    "    test_df['text'] = test_df.progress_apply(\n",
    "        lambda row: prepare_text(row[f'tokens_{var}'], row[f'Bigrams_{var}'], row[f'Trigrams_{var}'], use_ngrams=True), axis=1\n",
    "    )\n",
    "    \n",
    "    X_train = train_df['text']\n",
    "    X_test = test_df['text']\n",
    "    \n",
    "    # Multi-class (16 types)\n",
    "    print(\"üß† Training multi-class model with balanced class weights...\")\n",
    "    y_train_multi = train_df['type']\n",
    "    y_test_multi = test_df['type']\n",
    "    \n",
    "    pipeline_multi = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1,3))),\n",
    "        ('clf', LinearSVC(class_weight='balanced', max_iter=10000))  # SVM classifier\n",
    "    ])\n",
    "    \n",
    "    pipeline_multi.fit(X_train, y_train_multi)\n",
    "    y_pred_multi = pipeline_multi.predict(X_test)\n",
    "    \n",
    "    acc_multi = accuracy_score(y_test_multi, y_pred_multi)\n",
    "    f1_multi = f1_score(y_test_multi, y_pred_multi, average='weighted')\n",
    "    \n",
    "    results_multi[var] = {'accuracy': acc_multi, 'f1': f1_multi}\n",
    "    print(f\"Multi-class - Accuracy: {acc_multi:.4f}, F1: {f1_multi:.4f}\")\n",
    "    print(classification_report(y_test_multi, y_pred_multi))\n",
    "    \n",
    "    # Save model\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    joblib.dump(pipeline_multi, f'models/multi_{var}.pkl')\n",
    "    \n",
    "    # Binary classifiers for each dimension\n",
    "    for dim in ['IE', 'NS', 'FT', 'JP']:\n",
    "        print(f\"üß† Training binary model for {dim} with balanced class weights...\")\n",
    "        y_train_bin = train_df[dim]\n",
    "        y_test_bin = test_df[dim]\n",
    "        \n",
    "        pipeline_bin = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1,3))),\n",
    "            ('clf', LinearSVC(class_weight='balanced', max_iter=10000))  # SVM classifier\n",
    "        ])\n",
    "        \n",
    "        pipeline_bin.fit(X_train, y_train_bin)\n",
    "        y_pred_bin = pipeline_bin.predict(X_test)\n",
    "        \n",
    "        acc_bin = accuracy_score(y_test_bin, y_pred_bin)\n",
    "        f1_bin = f1_score(y_test_bin, y_pred_bin, average='weighted')\n",
    "        \n",
    "        results_binary[dim][var] = {'accuracy': acc_bin, 'f1': f1_bin}\n",
    "        print(f\"{dim} - Accuracy: {acc_bin:.4f}, F1: {f1_bin:.4f}\")\n",
    "        print(classification_report(y_test_bin, y_pred_bin))\n",
    "        \n",
    "        # Save model\n",
    "        joblib.dump(pipeline_bin, f'models/binary_{dim}_{var}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d5d557",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Compare results\n",
    "print(\"\\nüìä Comparison of Multi-class Results:\")\n",
    "for var, res in results_multi.items():\n",
    "    print(f\"{var}: Accuracy={res['accuracy']:.4f}, F1={res['f1']:.4f}\")\n",
    "\n",
    "for dim in ['IE', 'NS', 'FT', 'JP']:\n",
    "    print(f\"\\nüìä Comparison of Binary {dim} Results:\")\n",
    "    for var, res in results_binary[dim].items():\n",
    "        print(f\"{var}: Accuracy={res['accuracy']:.4f}, F1={res['f1']:.4f}\")\n",
    "\n",
    "print(\"‚úÖ Training and evaluation complete! Models saved in models/ directory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
