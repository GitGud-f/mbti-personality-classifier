{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa4NU2oEnm1f"
      },
      "source": [
        "# Import Needed Libs and Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "61vI9R8LnodJ"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import wordnet\n",
        "import emoji\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.util import ngrams\n",
        "import matplotlib\n",
        "import contractions\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from typing import Tuple\n",
        "from typing import List\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/johann/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /home/johann/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /home/johann/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /home/johann/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mnotebook controller is DISPOSED. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "STOP_WORDS = set(stopwords.words('english'))\n",
        "WNL = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TZEhdXs_nqGH",
        "outputId": "1d22646f-4003-47c8-8ca1-0a8ce2435ee6"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"../data/raw/mbti_1.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 6940, Test size: 1735\n"
          ]
        }
      ],
      "source": [
        "# Split the data first to avoid data leakage\n",
        "train_df, test_df = train_test_split(\n",
        "    df, \n",
        "    test_size=0.2, \n",
        "    random_state=42, \n",
        "    stratify=df['type']\n",
        ")\n",
        "print(f\"Train size: {len(train_df)}, Test size: {len(test_df)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhjNTbhZrIG4"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "saFXXoNlrLMn",
        "outputId": "c0f9656f-36fc-4742-e9a7-cb9a7d082873"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>8675</td>\n",
              "      <td>8675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>16</td>\n",
              "      <td>8675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>INFP</td>\n",
              "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1832</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        type                                              posts\n",
              "count   8675                                               8675\n",
              "unique    16                                               8675\n",
              "top     INFP  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
              "freq    1832                                                  1"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "yPguO6iNv7w-",
        "outputId": "c54d2380-c5a2-4336-d413-a1f266649b61"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"'http://www.youtube.com/watch?v=qsXHcwe3krw|||http://41.media.tumblr.com/tumblr_lfouy03PMA1qa1rooo1_500.jpg|||enfp and intj moments  https://www.youtube.com/watch?v=iz7lE1g4XM4  sportscenter not top ten plays  https://www.youtube.com/watch?v=uCdfze1etec  pranks|||What has been the most life-changing experience in your life?|||http://www.youtube.com/watch?v=vXZeYwwRDw8   http://www.youtube.com/watch?v=u8ejam5DP3E  On repeat for most of today.|||May the PerC Experience immerse you.|||The last thing my INFJ friend posted on his facebook before committing suicide the next day. Rest in peace~   http://vimeo.com/22842206|||Hello ENFJ7. Sorry to hear of your distress. It's only natural for a relationship to not be perfection all the time in every moment of existence. Try to figure the hard times as times of growth, as...|||84389  84390  http://wallpaperpassion.com/upload/23700/friendship-boy-and-girl-wallpaper.jpg  http://assets.dornob.com/wp-content/uploads/2010/04/round-home-design.jpg ...|||Welcome and stuff.|||http://playeressence.com/wp-content/uploads/2013/08/RED-red-the-pokemon-master-32560474-450-338.jpg  Game. Set. Match.|||Prozac, wellbrutin, at least thirty minutes of moving your legs (and I don't mean moving them while sitting in your same desk chair), weed in moderation (maybe try edibles as a healthier alternative...|||Basically come up with three items you've determined that each type (or whichever types you want to do) would more than likely use, given each types' cognitive functions and whatnot, when left by...|||All things in moderation.  Sims is indeed a video game, and a good one at that. Note: a good one at that is somewhat subjective in that I am not completely promoting the death of any given Sim...|||Dear ENFP:  What were your favorite video games growing up and what are your now, current favorite video games? :cool:|||https://www.youtube.com/watch?v=QyPqT8umzmY|||It appears to be too late. :sad:|||There's someone out there for everyone.|||Wait... I thought confidence was a good thing.|||I just cherish the time of solitude b/c i revel within my inner world more whereas most other time i'd be workin... just enjoy the me time while you can. Don't worry, people will always be around to...|||Yo entp ladies... if you're into a complimentary personality,well, hey.|||... when your main social outlet is xbox live conversations and even then you verbally fatigue quickly.|||http://www.youtube.com/watch?v=gDhy7rdfm14  I really dig the part from 1:46 to 2:50|||http://www.youtube.com/watch?v=msqXffgh7b8|||Banned because this thread requires it of me.|||Get high in backyard, roast and eat marshmellows in backyard while conversing over something intellectual, followed by massages and kisses.|||http://www.youtube.com/watch?v=Mw7eoU3BMbE|||http://www.youtube.com/watch?v=4V2uYORhQOk|||http://www.youtube.com/watch?v=SlVmgFQQ0TI|||Banned for too many b's in that sentence. How could you! Think of the B!|||Banned for watching movies in the corner with the dunces.|||Banned because Health class clearly taught you nothing about peer pressure.|||Banned for a whole host of reasons!|||http://www.youtube.com/watch?v=IRcrv41hgz4|||1) Two baby deer on left and right munching on a beetle in the middle.  2) Using their own blood, two cavemen diary today's latest happenings on their designated cave diary wall.  3) I see it as...|||a pokemon world  an infj society  everyone becomes an optimist|||49142|||http://www.youtube.com/watch?v=ZRCEq_JFeFM|||http://discovermagazine.com/2012/jul-aug/20-things-you-didnt-know-about-deserts/desert.jpg|||http://oyster.ignimgs.com/mediawiki/apis.ign.com/pokemon-silver-version/d/dd/Ditto.gif|||http://www.serebii.net/potw-dp/Scizor.jpg|||Not all artists are artists because they draw. It's the idea that counts in forming something of your own... like a signature.|||Welcome to the robot ranks, person who downed my self-esteem cuz I'm not an avid signature artist like herself. :proud:|||Banned for taking all the room under my bed. Ya gotta learn to share with the roaches.|||http://www.youtube.com/watch?v=w8IgImn57aQ|||Banned for being too much of a thundering, grumbling kind of storm... yep.|||Ahh... old high school music I haven't heard in ages.   http://www.youtube.com/watch?v=dcCRUPCdB1w|||I failed a public speaking class a few years ago and I've sort of learned what I could do better were I to be in that position again. A big part of my failure was just overloading myself with too...|||I like this person's mentality. He's a confirmed INTJ by the way. http://www.youtube.com/watch?v=hGKLI-GEc6M|||Move to the Denver area and start a new life for myself.'\""
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.posts[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "FpOSUh9nxZy2"
      },
      "outputs": [],
      "source": [
        "def clean_text(text: str) -> str:\n",
        "    \"\"\"Clean raw text by removing URLs, emojis, mentions, and MBTI codes.\"\"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'https?\\S+|www\\S+', '', text)\n",
        "    text = emoji.replace_emoji(text, replace='')\n",
        "    text = re.sub(r'@\\w+|#', '', text)\n",
        "    text = re.sub(r\"[^a-z\\']\", ' ', text)\n",
        "    # Remove MBTI type codes (e.g., INFJ, ENTP) to avoid leaking information\n",
        "    text = re.sub(r'\\b(I|E)(N|S)(F|T)(J|P)(s?)\\b', '', text, flags=re.IGNORECASE)\n",
        "    # Remove common footer\n",
        "    text = re.sub(r'\\bsent (from )?my \\w+(\\s\\w+)? using tapatalk\\b', '', text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r'w w w', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "PrV9RfpM1FTO"
      },
      "outputs": [],
      "source": [
        "def preprocess_posts(posts_str: str) -> str:\n",
        "    \"\"\"Split multi-post string (separated by '|||'), clean each, and join.\"\"\"\n",
        "    posts = posts_str.split('|||')\n",
        "    cleaned_posts = [clean_text(post) for post in posts]\n",
        "    joined = ' '.join(cleaned_posts)\n",
        "    return re.sub(r'\\s+', ' ', joined).strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "W33jZx375gCS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaning posts for train...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6940/6940 [01:04<00:00, 107.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaning posts for test...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1735/1735 [00:16<00:00, 108.25it/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"Cleaning posts for train...\")\n",
        "tqdm.pandas()\n",
        "train_df['cleaned_posts'] = train_df['posts'].progress_apply(preprocess_posts)\n",
        "\n",
        "print(\"Cleaning posts for test...\")\n",
        "test_df['cleaned_posts'] = test_df['posts'].progress_apply(preprocess_posts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "m7-p43UNT88f"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def encode_mbti_type(mbti: str) -> Tuple[int, int, int, int]:\n",
        "    \"\"\"\n",
        "    Encode MBTI type as 4 binary dimensions:\n",
        "    I/E â†’ 1/0, N/S â†’ 1/0, F/T â†’ 1/0, J/P â†’ 1/0\n",
        "    \"\"\"\n",
        "    return (\n",
        "        1 if mbti[0] == 'I' else 0,\n",
        "        1 if mbti[1] == 'N' else 0,\n",
        "        1 if mbti[2] == 'F' else 0,\n",
        "        1 if mbti[3] == 'J' else 0,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "1RoFT_0ZUM2l"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding MBTI types for train...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6940/6940 [00:00<00:00, 124843.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoding MBTI types for test...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1735/1735 [00:00<00:00, 352164.03it/s]\n"
          ]
        }
      ],
      "source": [
        "# Encode labels for train and test\n",
        "print(\"Encoding MBTI types for train...\")\n",
        "train_df[['IE', 'NS', 'FT', 'JP']] = pd.DataFrame(\n",
        "    train_df['type'].progress_apply(encode_mbti_type).tolist(),\n",
        "    index=train_df.index\n",
        ")\n",
        "\n",
        "print(\"Encoding MBTI types for test...\")\n",
        "test_df[['IE', 'NS', 'FT', 'JP']] = pd.DataFrame(\n",
        "    test_df['type'].progress_apply(encode_mbti_type).tolist(),\n",
        "    index=test_df.index\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_______________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/johann/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /home/johann/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /home/johann/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /home/johann/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /home/johann/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /home/johann/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizing and lemmatizing for train...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/6940 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6940/6940 [04:40<00:00, 24.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizing and lemmatizing for test...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1735/1735 [01:10<00:00, 24.47it/s]\n"
          ]
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "def get_wordnet_pos(tag: str) -> str:\n",
        "    \"\"\"Map POS tag to WordNet format for lemmatization.\"\"\"\n",
        "    if tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN\n",
        "\n",
        "def tokenize_text(text: str) -> List[str]:\n",
        "    \"\"\"Expand contractions, tokenize, remove stopwords, and lemmatize.\"\"\"\n",
        "    fixed = contractions.fix(text)\n",
        "    tokens = word_tokenize(fixed)\n",
        "    filtered_tokens = [word for word in tokens if word.lower() not in STOP_WORDS]\n",
        "    pos_tags = nltk.pos_tag(filtered_tokens)\n",
        "    lemmatized = [\n",
        "        WNL.lemmatize(token, pos=get_wordnet_pos(pos))\n",
        "        for token, pos in pos_tags\n",
        "    ]\n",
        "    return lemmatized\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "\n",
        "print(\"Tokenizing and lemmatizing for train...\")\n",
        "train_df['tokens'] = train_df['cleaned_posts'].progress_apply(tokenize_text)\n",
        "\n",
        "print(\"Tokenizing and lemmatizing for test...\")\n",
        "test_df['tokens'] = test_df['cleaned_posts'].progress_apply(tokenize_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "      <th>cleaned_posts</th>\n",
              "      <th>IE</th>\n",
              "      <th>NS</th>\n",
              "      <th>FT</th>\n",
              "      <th>JP</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8331</th>\n",
              "      <td>INFP</td>\n",
              "      <td>'this is actually exactly what i expected!  :l...</td>\n",
              "      <td>'this is actually exactly what i expected laug...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>['this, actually, exactly, expect, laugh, intr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1290</th>\n",
              "      <td>ISTP</td>\n",
              "      <td>'Nope.  Not now, not ever.  I'm too busy with ...</td>\n",
              "      <td>'nope not now not ever i'm too busy with work ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['nope, ever, busy, work, cause, adrenaline, r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1982</th>\n",
              "      <td>ENFJ</td>\n",
              "      <td>'Yes peace is the absence of conflict - your I...</td>\n",
              "      <td>'yes peace is the absence of conflict your fri...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>['yes, peace, absence, conflict, friend, suxx,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>769</th>\n",
              "      <td>INFP</td>\n",
              "      <td>'I apologize for the delayed response, but tha...</td>\n",
              "      <td>'i apologize for the delayed response but than...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[', apologize, delay, response, thank, taking,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8339</th>\n",
              "      <td>INFP</td>\n",
              "      <td>'Nightglow, I can't even imagine what you must...</td>\n",
              "      <td>'nightglow i can't even imagine what you must ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>['nightglow, even, imagine, must, struggle, ri...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      type                                              posts  \\\n",
              "8331  INFP  'this is actually exactly what i expected!  :l...   \n",
              "1290  ISTP  'Nope.  Not now, not ever.  I'm too busy with ...   \n",
              "1982  ENFJ  'Yes peace is the absence of conflict - your I...   \n",
              "769   INFP  'I apologize for the delayed response, but tha...   \n",
              "8339  INFP  'Nightglow, I can't even imagine what you must...   \n",
              "\n",
              "                                          cleaned_posts  IE  NS  FT  JP  \\\n",
              "8331  'this is actually exactly what i expected laug...   1   1   1   0   \n",
              "1290  'nope not now not ever i'm too busy with work ...   1   0   0   0   \n",
              "1982  'yes peace is the absence of conflict your fri...   0   1   1   1   \n",
              "769   'i apologize for the delayed response but than...   1   1   1   0   \n",
              "8339  'nightglow i can't even imagine what you must ...   1   1   1   0   \n",
              "\n",
              "                                                 tokens  \n",
              "8331  ['this, actually, exactly, expect, laugh, intr...  \n",
              "1290  ['nope, ever, busy, work, cause, adrenaline, r...  \n",
              "1982  ['yes, peace, absence, conflict, friend, suxx,...  \n",
              "769   [', apologize, delay, response, thank, taking,...  \n",
              "8339  ['nightglow, even, imagine, must, struggle, ri...  "
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "4N85Mj8TVLiw"
      },
      "outputs": [],
      "source": [
        "def generate_ngrams(tokens: List[str]) -> Tuple[List, List, List]:\n",
        "    \"\"\"Generate unigrams, bigrams, and trigrams from token list.\"\"\"\n",
        "    unigrams = list(ngrams(tokens, 1))\n",
        "    bigrams = list(ngrams(tokens, 2))\n",
        "    trigrams = list(ngrams(tokens, 3))\n",
        "    return unigrams, bigrams, trigrams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "oleXaYQFVV95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“Š Generating n-grams for train...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6940/6940 [00:04<00:00, 1567.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“Š Generating n-grams for test...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1735/1735 [00:01<00:00, 1067.53it/s]\n"
          ]
        }
      ],
      "source": [
        "# Generate n-grams for train and test\n",
        "print(\"ðŸ“Š Generating n-grams for train...\")\n",
        "ngram_results_train = train_df['tokens'].progress_apply(generate_ngrams)\n",
        "train_df[['Unigrams', 'Bigrams', 'Trigrams']] = pd.DataFrame(\n",
        "    ngram_results_train.tolist(), index=train_df.index\n",
        ")\n",
        "\n",
        "print(\"ðŸ“Š Generating n-grams for test...\")\n",
        "ngram_results_test = test_df['tokens'].progress_apply(generate_ngrams)\n",
        "test_df[['Unigrams', 'Bigrams', 'Trigrams']] = pd.DataFrame(\n",
        "    ngram_results_test.tolist(), index=test_df.index\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "NTfoP2OdVi9k",
        "outputId": "a28be060-5173-43bc-8df5-b19b254b84c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word Count Statistics (Train):\n",
            "count    6940.000000\n",
            "mean      595.601441\n",
            "std       139.623337\n",
            "min         1.000000\n",
            "25%       517.000000\n",
            "50%       620.000000\n",
            "75%       699.000000\n",
            "max       906.000000\n",
            "Name: word_count, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Word count stats (on train for EDA)\n",
        "train_df['word_count'] = train_df['tokens'].apply(len)\n",
        "print(\"Word Count Statistics (Train):\")\n",
        "print(train_df['word_count'].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "      <th>cleaned_posts</th>\n",
              "      <th>IE</th>\n",
              "      <th>NS</th>\n",
              "      <th>FT</th>\n",
              "      <th>JP</th>\n",
              "      <th>tokens</th>\n",
              "      <th>Unigrams</th>\n",
              "      <th>Bigrams</th>\n",
              "      <th>Trigrams</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8331</th>\n",
              "      <td>INFP</td>\n",
              "      <td>'this is actually exactly what i expected!  :l...</td>\n",
              "      <td>'this is actually exactly what i expected laug...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>['this, actually, exactly, expect, laugh, intr...</td>\n",
              "      <td>[('this,), (actually,), (exactly,), (expect,),...</td>\n",
              "      <td>[('this, actually), (actually, exactly), (exac...</td>\n",
              "      <td>[('this, actually, exactly), (actually, exactl...</td>\n",
              "      <td>722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1290</th>\n",
              "      <td>ISTP</td>\n",
              "      <td>'Nope.  Not now, not ever.  I'm too busy with ...</td>\n",
              "      <td>'nope not now not ever i'm too busy with work ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['nope, ever, busy, work, cause, adrenaline, r...</td>\n",
              "      <td>[('nope,), (ever,), (busy,), (work,), (cause,)...</td>\n",
              "      <td>[('nope, ever), (ever, busy), (busy, work), (w...</td>\n",
              "      <td>[('nope, ever, busy), (ever, busy, work), (bus...</td>\n",
              "      <td>638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1982</th>\n",
              "      <td>ENFJ</td>\n",
              "      <td>'Yes peace is the absence of conflict - your I...</td>\n",
              "      <td>'yes peace is the absence of conflict your fri...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>['yes, peace, absence, conflict, friend, suxx,...</td>\n",
              "      <td>[('yes,), (peace,), (absence,), (conflict,), (...</td>\n",
              "      <td>[('yes, peace), (peace, absence), (absence, co...</td>\n",
              "      <td>[('yes, peace, absence), (peace, absence, conf...</td>\n",
              "      <td>578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>769</th>\n",
              "      <td>INFP</td>\n",
              "      <td>'I apologize for the delayed response, but tha...</td>\n",
              "      <td>'i apologize for the delayed response but than...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[', apologize, delay, response, thank, taking,...</td>\n",
              "      <td>[(',), (apologize,), (delay,), (response,), (t...</td>\n",
              "      <td>[(', apologize), (apologize, delay), (delay, r...</td>\n",
              "      <td>[(', apologize, delay), (apologize, delay, res...</td>\n",
              "      <td>636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8339</th>\n",
              "      <td>INFP</td>\n",
              "      <td>'Nightglow, I can't even imagine what you must...</td>\n",
              "      <td>'nightglow i can't even imagine what you must ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>['nightglow, even, imagine, must, struggle, ri...</td>\n",
              "      <td>[('nightglow,), (even,), (imagine,), (must,), ...</td>\n",
              "      <td>[('nightglow, even), (even, imagine), (imagine...</td>\n",
              "      <td>[('nightglow, even, imagine), (even, imagine, ...</td>\n",
              "      <td>701</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      type                                              posts  \\\n",
              "8331  INFP  'this is actually exactly what i expected!  :l...   \n",
              "1290  ISTP  'Nope.  Not now, not ever.  I'm too busy with ...   \n",
              "1982  ENFJ  'Yes peace is the absence of conflict - your I...   \n",
              "769   INFP  'I apologize for the delayed response, but tha...   \n",
              "8339  INFP  'Nightglow, I can't even imagine what you must...   \n",
              "\n",
              "                                          cleaned_posts  IE  NS  FT  JP  \\\n",
              "8331  'this is actually exactly what i expected laug...   1   1   1   0   \n",
              "1290  'nope not now not ever i'm too busy with work ...   1   0   0   0   \n",
              "1982  'yes peace is the absence of conflict your fri...   0   1   1   1   \n",
              "769   'i apologize for the delayed response but than...   1   1   1   0   \n",
              "8339  'nightglow i can't even imagine what you must ...   1   1   1   0   \n",
              "\n",
              "                                                 tokens  \\\n",
              "8331  ['this, actually, exactly, expect, laugh, intr...   \n",
              "1290  ['nope, ever, busy, work, cause, adrenaline, r...   \n",
              "1982  ['yes, peace, absence, conflict, friend, suxx,...   \n",
              "769   [', apologize, delay, response, thank, taking,...   \n",
              "8339  ['nightglow, even, imagine, must, struggle, ri...   \n",
              "\n",
              "                                               Unigrams  \\\n",
              "8331  [('this,), (actually,), (exactly,), (expect,),...   \n",
              "1290  [('nope,), (ever,), (busy,), (work,), (cause,)...   \n",
              "1982  [('yes,), (peace,), (absence,), (conflict,), (...   \n",
              "769   [(',), (apologize,), (delay,), (response,), (t...   \n",
              "8339  [('nightglow,), (even,), (imagine,), (must,), ...   \n",
              "\n",
              "                                                Bigrams  \\\n",
              "8331  [('this, actually), (actually, exactly), (exac...   \n",
              "1290  [('nope, ever), (ever, busy), (busy, work), (w...   \n",
              "1982  [('yes, peace), (peace, absence), (absence, co...   \n",
              "769   [(', apologize), (apologize, delay), (delay, r...   \n",
              "8339  [('nightglow, even), (even, imagine), (imagine...   \n",
              "\n",
              "                                               Trigrams  word_count  \n",
              "8331  [('this, actually, exactly), (actually, exactl...         722  \n",
              "1290  [('nope, ever, busy), (ever, busy, work), (bus...         638  \n",
              "1982  [('yes, peace, absence), (peace, absence, conf...         578  \n",
              "769   [(', apologize, delay), (apologize, delay, res...         636  \n",
              "8339  [('nightglow, even, imagine), (even, imagine, ...         701  "
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_class_distribution(df: pd.DataFrame):\n",
        "    # 16 types\n",
        "    type_counts = df['type'].value_counts()\n",
        "    print(\"MBTI Type Distribution:\\n\", type_counts)\n",
        "    \n",
        "    # Dichotomies (using binary encodings)\n",
        "    dichotomy_counts = {\n",
        "        'I/E': df['IE'].value_counts(normalize=True) * 100,  # 1=I, 0=E\n",
        "        'N/S': df['NS'].value_counts(normalize=True) * 100,  # 1=N, 0=S\n",
        "        'F/T': df['FT'].value_counts(normalize=True) * 100,  # 1=F, 0=T\n",
        "        'J/P': df['JP'].value_counts(normalize=True) * 100,  # 1=J, 0=P\n",
        "    }\n",
        "    print(\"Dichotomy Percentages:\\n\", pd.DataFrame(dichotomy_counts))\n",
        "    \n",
        "    # Plot 16 types\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.barplot(x=type_counts.index, y=type_counts.values)\n",
        "    plt.title('MBTI Type Distribution')\n",
        "    plt.xlabel('Type')\n",
        "    plt.ylabel('Count')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MBTI Type Distribution:\n",
            " type\n",
            "INFP    1466\n",
            "INFJ    1176\n",
            "INTP    1043\n",
            "INTJ     873\n",
            "ENTP     548\n",
            "ENFP     540\n",
            "ISTP     270\n",
            "ISFP     217\n",
            "ENTJ     185\n",
            "ISTJ     164\n",
            "ENFJ     152\n",
            "ISFJ     133\n",
            "ESTP      71\n",
            "ESFP      38\n",
            "ESFJ      33\n",
            "ESTJ      31\n",
            "Name: count, dtype: int64\n",
            "Dichotomy Percentages:\n",
            "          I/E        N/S        F/T        J/P\n",
            "0  23.025937  13.789625  45.893372  60.417867\n",
            "1  76.974063  86.210375  54.106628  39.582133\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Perform analysis on train set for EDA\n",
        "analyze_class_distribution(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 6940, Test size: 1735\n"
          ]
        }
      ],
      "source": [
        "X_train = train_df['cleaned_posts']\n",
        "X_test = test_df['cleaned_posts']\n",
        "y_train = train_df[['IE', 'NS', 'FT', 'JP']]\n",
        "y_test = test_df[['IE', 'NS', 'FT', 'JP']]\n",
        "print(f\"Train size: {len(X_train)}, Test size: {len(X_test)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Feature Engineering Strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "def create_feature_combinations(X_train, X_test):\n",
        "    \"\"\"\n",
        "    Create multiple feature combinations for experimentation\n",
        "    \"\"\"\n",
        "    feature_sets = {}\n",
        "    \n",
        "    # Strategy 1: Unigrams only\n",
        "    uni_vectorizer = TfidfVectorizer(\n",
        "        max_features=10000,\n",
        "        ngram_range=(1, 1),\n",
        "        min_df=2,\n",
        "        max_df=0.8,\n",
        "        stop_words='english'\n",
        "    )\n",
        "    X_train_uni = uni_vectorizer.fit_transform(X_train)\n",
        "    X_test_uni = uni_vectorizer.transform(X_test)\n",
        "    feature_sets['unigrams'] = (X_train_uni, X_test_uni, uni_vectorizer)\n",
        "    \n",
        "    # Strategy 2: Unigrams + Bigrams\n",
        "    uni_bi_vectorizer = TfidfVectorizer(\n",
        "        max_features=15000,\n",
        "        ngram_range=(1, 2),\n",
        "        min_df=2,\n",
        "        max_df=0.8,\n",
        "        stop_words='english'\n",
        "    )\n",
        "    X_train_uni_bi = uni_bi_vectorizer.fit_transform(X_train)\n",
        "    X_test_uni_bi = uni_bi_vectorizer.transform(X_test)\n",
        "    feature_sets['unigrams_bigrams'] = (X_train_uni_bi, X_test_uni_bi, uni_bi_vectorizer)\n",
        "    \n",
        "    # Strategy 3: Unigrams + Bigrams + Trigrams\n",
        "    full_vectorizer = TfidfVectorizer(\n",
        "        max_features=20000,\n",
        "        ngram_range=(1, 3),\n",
        "        min_df=3,  # Higher min_df for trigrams\n",
        "        max_df=0.8,\n",
        "        stop_words='english'\n",
        "    )\n",
        "    X_train_full = full_vectorizer.fit_transform(X_train)\n",
        "    X_test_full = full_vectorizer.transform(X_test)\n",
        "    feature_sets['all_ngrams'] = (X_train_full, X_test_full, full_vectorizer)\n",
        "    \n",
        "    # Strategy 4: Character n-grams (captures stylistic patterns)\n",
        "    char_vectorizer = TfidfVectorizer(\n",
        "        max_features=5000,\n",
        "        analyzer='char_wb',\n",
        "        ngram_range=(3, 5),\n",
        "        min_df=2\n",
        "    )\n",
        "    X_train_char = char_vectorizer.fit_transform(X_train)\n",
        "    X_test_char = char_vectorizer.transform(X_test)\n",
        "    feature_sets['char_ngrams'] = (X_train_char, X_test_char, char_vectorizer)\n",
        "    \n",
        "    return feature_sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. SVM Training Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "import scipy\n",
        "\n",
        "def train_svm_models(X_train, y_train, feature_sets):\n",
        "    \"\"\"\n",
        "    Train SVM models with different feature combinations and hyperparameter tuning\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "    \n",
        "    # Hyperparameter grid for SVM\n",
        "    param_grid = {\n",
        "        'estimator__C': [0.1, 1, 10, 100],\n",
        "        'estimator__class_weight': [None, 'balanced']\n",
        "    }\n",
        "    \n",
        "    for feature_name, (X_train_feat, X_test_feat, vectorizer) in feature_sets.items():\n",
        "        print(f\"\\n=== Training with {feature_name} ===\")\n",
        "        \n",
        "        # Feature selection for high-dimensional spaces\n",
        "        if X_train_feat.shape[1] > 5000:\n",
        "            selector = SelectKBest(chi2, k=min(5000, X_train_feat.shape[1]))\n",
        "            X_train_selected = selector.fit_transform(X_train_feat, y_train.iloc[:, 0])\n",
        "            X_test_selected = selector.transform(X_test_feat)\n",
        "        else:\n",
        "            X_train_selected = X_train_feat\n",
        "            X_test_selected = X_test_feat\n",
        "        \n",
        "        # Create MultiOutput SVM pipeline\n",
        "        base_svm = LinearSVC(\n",
        "            random_state=42,\n",
        "            max_iter=2000,\n",
        "            dual=True  # Better for n_features > n_samples\n",
        "        )\n",
        "        \n",
        "        multi_svm = MultiOutputClassifier(base_svm)\n",
        "        \n",
        "        # Grid search for hyperparameter tuning\n",
        "        grid_search = GridSearchCV(\n",
        "            multi_svm,\n",
        "            param_grid,\n",
        "            cv=3,\n",
        "            scoring='accuracy',\n",
        "            n_jobs=-1,\n",
        "            verbose=1\n",
        "        )\n",
        "        \n",
        "        # Train model\n",
        "        grid_search.fit(X_train_selected, y_train)\n",
        "        \n",
        "        # Store results\n",
        "        results[feature_name] = {\n",
        "            'model': grid_search.best_estimator_,\n",
        "            'vectorizer': vectorizer,\n",
        "            'selector': selector if X_train_feat.shape[1] > 5000 else None,\n",
        "            'best_params': grid_search.best_params_,\n",
        "            'best_score': grid_search.best_score_,\n",
        "            'feature_set': (X_train_selected, X_test_selected)\n",
        "        }\n",
        "        \n",
        "        print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "        print(f\"Best CV score: {grid_search.best_score_:.4f}\")\n",
        "    \n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Ensemble Strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "\n",
        "class FeatureWeightedEnsemble(BaseEstimator, ClassifierMixin):\n",
        "    \"\"\"\n",
        "    Custom ensemble that weights predictions based on feature set performance\n",
        "    \"\"\"\n",
        "    def __init__(self, models, weights=None):\n",
        "        self.models = models\n",
        "        self.weights = weights if weights else [1/len(models)] * len(models)\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        # Models are already trained\n",
        "        return self\n",
        "    \n",
        "    def predict(self, X):\n",
        "        predictions = []\n",
        "        for (name, model_data), weight in zip(self.models.items(), self.weights):\n",
        "            X_feat = model_data['feature_set'][1]  # Use test features\n",
        "            pred = model_data['model'].predict(X_feat)\n",
        "            predictions.append(pred * weight)\n",
        "        \n",
        "        # Weighted average\n",
        "        weighted_avg = np.sum(predictions, axis=0) / np.sum(self.weights)\n",
        "        return (weighted_avg > 0.5).astype(int)\n",
        "    \n",
        "    def predict_proba(self, X):\n",
        "        # For models that support probability estimates\n",
        "        probas = []\n",
        "        for (name, model_data), weight in zip(self.models.items(), self.weights):\n",
        "            X_feat = model_data['feature_set'][1]\n",
        "            # For LinearSVC, you might need CalibratedClassifierCV for probabilities\n",
        "            try:\n",
        "                proba = model_data['model'].predict_proba(X_feat)\n",
        "                probas.append(proba * weight)\n",
        "            except:\n",
        "                # Fallback to decision function\n",
        "                decision = model_data['model'].decision_function(X_feat)\n",
        "                proba = 1 / (1 + np.exp(-decision))\n",
        "                probas.append(proba * weight)\n",
        "        \n",
        "        return np.sum(probas, axis=0) / np.sum(self.weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Complete Evaluation Framework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_mbti_predictions(y_true, y_pred, dimension_names=['IE', 'NS', 'FT', 'JP']):\n",
        "    \"\"\"\n",
        "    Comprehensive evaluation for MBTI prediction\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "    \n",
        "    # Overall accuracy\n",
        "    overall_accuracy = accuracy_score(y_true, y_pred)\n",
        "    results['overall_accuracy'] = overall_accuracy\n",
        "    \n",
        "    # Per-dimension accuracy\n",
        "    dimension_accuracies = {}\n",
        "    for i, dim in enumerate(dimension_names):\n",
        "        dim_accuracy = accuracy_score(y_true.iloc[:, i], y_pred[:, i])\n",
        "        dimension_accuracies[dim] = dim_accuracy\n",
        "        print(f\"{dim} Accuracy: {dim_accuracy:.4f}\")\n",
        "    \n",
        "    results['dimension_accuracies'] = dimension_accuracies\n",
        "    \n",
        "    # Exact type match (all 4 dimensions correct)\n",
        "    exact_matches = np.all(y_true.values == y_pred, axis=1)\n",
        "    exact_match_rate = np.mean(exact_matches)\n",
        "    results['exact_match_rate'] = exact_match_rate\n",
        "    print(f\"Exact Type Match Rate: {exact_match_rate:.4f}\")\n",
        "    \n",
        "    # Partial matches (3 out of 4 dimensions correct)\n",
        "    partial_matches_3 = np.sum(y_true.values == y_pred, axis=1) >= 3\n",
        "    partial_match_3_rate = np.mean(partial_matches_3)\n",
        "    results['partial_match_3_rate'] = partial_match_3_rate\n",
        "    print(f\"Partial Match (3/4) Rate: {partial_match_3_rate:.4f}\")\n",
        "    \n",
        "    return results\n",
        "\n",
        "def run_complete_evaluation():\n",
        "    \"\"\"\n",
        "    Run the complete SVM evaluation pipeline\n",
        "    \"\"\"\n",
        "    # 1. Create feature combinations\n",
        "    print(\"Step 1: Creating feature combinations...\")\n",
        "    feature_sets = create_feature_combinations(X_train, X_test)\n",
        "    \n",
        "    # 2. Train SVM models\n",
        "    print(\"\\nStep 2: Training SVM models...\")\n",
        "    trained_models = train_svm_models(X_train, y_train, feature_sets)\n",
        "    \n",
        "    # 3. Evaluate individual models\n",
        "    print(\"\\nStep 3: Evaluating individual models...\")\n",
        "    individual_results = {}\n",
        "    for feature_name, model_data in trained_models.items():\n",
        "        print(f\"\\n--- Results for {feature_name} ---\")\n",
        "        X_test_feat = model_data['feature_set'][1]\n",
        "        y_pred = model_data['model'].predict(X_test_feat)\n",
        "        results = evaluate_mbti_predictions(y_test, y_pred)\n",
        "        individual_results[feature_name] = results\n",
        "    \n",
        "    # 4. Create ensemble\n",
        "    print(\"\\nStep 4: Creating ensemble model...\")\n",
        "    # Weight models by their overall accuracy\n",
        "    weights = [individual_results[name]['overall_accuracy'] for name in trained_models.keys()]\n",
        "    ensemble = FeatureWeightedEnsemble(trained_models, weights)\n",
        "    \n",
        "    # 5. Evaluate ensemble\n",
        "    print(\"\\nStep 5: Evaluating ensemble model...\")\n",
        "    y_pred_ensemble = ensemble.predict(X_test)\n",
        "    ensemble_results = evaluate_mbti_predictions(y_test, y_pred_ensemble)\n",
        "    \n",
        "    return {\n",
        "        'individual_results': individual_results,\n",
        "        'ensemble_results': ensemble_results,\n",
        "        'trained_models': trained_models,\n",
        "        'ensemble': ensemble\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. Implementation and Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1: Creating feature combinations...\n",
            "\n",
            "Step 2: Training SVM models...\n",
            "\n",
            "=== Training with unigrams ===\n",
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
            "Best parameters: {'estimator__C': 1, 'estimator__class_weight': None}\n",
            "Best CV score: 0.3612\n",
            "\n",
            "=== Training with unigrams_bigrams ===\n",
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/media/johann/CP/Python/notebooks/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/media/johann/CP/Python/notebooks/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/media/johann/CP/Python/notebooks/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters: {'estimator__C': 1, 'estimator__class_weight': None}\n",
            "Best CV score: 0.3755\n",
            "\n",
            "=== Training with all_ngrams ===\n",
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/media/johann/CP/Python/notebooks/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/media/johann/CP/Python/notebooks/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/media/johann/CP/Python/notebooks/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/media/johann/CP/Python/notebooks/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters: {'estimator__C': 1, 'estimator__class_weight': None}\n",
            "Best CV score: 0.3769\n",
            "\n",
            "=== Training with char_ngrams ===\n",
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/media/johann/CP/Python/notebooks/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/media/johann/CP/Python/notebooks/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/media/johann/CP/Python/notebooks/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/media/johann/CP/Python/notebooks/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/media/johann/CP/Python/notebooks/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/media/johann/CP/Python/notebooks/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/media/johann/CP/Python/notebooks/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/media/johann/CP/Python/notebooks/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/media/johann/CP/Python/notebooks/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/media/johann/CP/Python/notebooks/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/media/johann/CP/Python/notebooks/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/media/johann/CP/Python/notebooks/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/media/johann/CP/Python/notebooks/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/media/johann/CP/Python/notebooks/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/media/johann/CP/Python/notebooks/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/media/johann/CP/Python/notebooks/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/media/johann/CP/Python/notebooks/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/media/johann/CP/Python/notebooks/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/media/johann/CP/Python/notebooks/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/media/johann/CP/Python/notebooks/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/media/johann/CP/Python/notebooks/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/media/johann/CP/Python/notebooks/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/media/johann/CP/Python/notebooks/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/media/johann/CP/Python/notebooks/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters: {'estimator__C': 1, 'estimator__class_weight': None}\n",
            "Best CV score: 0.3429\n",
            "\n",
            "Step 3: Evaluating individual models...\n",
            "\n",
            "--- Results for unigrams ---\n",
            "IE Accuracy: 0.7925\n",
            "NS Accuracy: 0.8565\n",
            "FT Accuracy: 0.7539\n",
            "JP Accuracy: 0.6605\n",
            "Exact Type Match Rate: 0.3522\n",
            "Partial Match (3/4) Rate: 0.7643\n",
            "\n",
            "--- Results for unigrams_bigrams ---\n",
            "IE Accuracy: 0.7850\n",
            "NS Accuracy: 0.8646\n",
            "FT Accuracy: 0.7545\n",
            "JP Accuracy: 0.6818\n",
            "Exact Type Match Rate: 0.3660\n",
            "Partial Match (3/4) Rate: 0.7775\n",
            "\n",
            "--- Results for all_ngrams ---\n",
            "IE Accuracy: 0.7914\n",
            "NS Accuracy: 0.8628\n",
            "FT Accuracy: 0.7585\n",
            "JP Accuracy: 0.6761\n",
            "Exact Type Match Rate: 0.3620\n",
            "Partial Match (3/4) Rate: 0.7839\n",
            "\n",
            "--- Results for char_ngrams ---\n",
            "IE Accuracy: 0.7902\n",
            "NS Accuracy: 0.8622\n",
            "FT Accuracy: 0.7735\n",
            "JP Accuracy: 0.6634\n",
            "Exact Type Match Rate: 0.3510\n",
            "Partial Match (3/4) Rate: 0.7850\n",
            "\n",
            "Step 4: Creating ensemble model...\n",
            "\n",
            "Step 5: Evaluating ensemble model...\n",
            "IE Accuracy: 0.7914\n",
            "NS Accuracy: 0.8640\n",
            "FT Accuracy: 0.7620\n",
            "JP Accuracy: 0.6859\n",
            "Exact Type Match Rate: 0.3735\n",
            "Partial Match (3/4) Rate: 0.7850\n",
            "\n",
            "=== Top features for unigrams ===\n",
            "\n",
            "IE dimension:\n",
            "Positive features:\n",
            "  ni: 2.1546\n",
            "  family: 1.7417\n",
            "  afraid: 1.6948\n",
            "  mind: 1.6135\n",
            "  relief: 1.6085\n",
            "  inferior: 1.5890\n",
            "  nature: 1.5674\n",
            "  lyrics: 1.5064\n",
            "  anime: 1.4711\n",
            "  games: 1.4581\n",
            "  organize: 1.4430\n",
            "  picky: 1.4329\n",
            "  circumstances: 1.4234\n",
            "  dislike: 1.3736\n",
            "  identifying: 1.3607\n",
            "  dealing: 1.3587\n",
            "  quiet: 1.3493\n",
            "  earth: 1.3489\n",
            "  spoken: 1.3419\n",
            "  wish: 1.3319\n",
            "Negative features:\n",
            "  ne: -2.6733\n",
            "  bored: -2.1496\n",
            "  ego: -1.8809\n",
            "  que: -1.7316\n",
            "  fun: -1.7294\n",
            "  term: -1.6776\n",
            "  matt: -1.5768\n",
            "  super: -1.5348\n",
            "  ntp: -1.5256\n",
            "  boredom: -1.5192\n",
            "  hire: -1.5164\n",
            "  cheer: -1.5086\n",
            "  associate: -1.4979\n",
            "  bond: -1.4745\n",
            "  reference: -1.4679\n",
            "  distracted: -1.4608\n",
            "  excited: -1.4498\n",
            "  chaos: -1.4359\n",
            "  money: -1.4320\n",
            "  flight: -1.4237\n",
            "\n",
            "NS dimension:\n",
            "Positive features:\n",
            "  nt: 2.0231\n",
            "  ideas: 1.9721\n",
            "  world: 1.7422\n",
            "  dark: 1.7275\n",
            "  debate: 1.5769\n",
            "  universe: 1.4575\n",
            "  humanity: 1.3876\n",
            "  makeup: 1.3782\n",
            "  wasnt: 1.3572\n",
            "  looked: 1.3352\n",
            "  worth: 1.3334\n",
            "  history: 1.3210\n",
            "  cope: 1.2709\n",
            "  intuition: 1.2610\n",
            "  tritype: 1.2565\n",
            "  alpha: 1.2531\n",
            "  likely: 1.2402\n",
            "  possibilities: 1.2364\n",
            "  partying: 1.2228\n",
            "  nts: 1.2174\n",
            "Negative features:\n",
            "  rant: -2.9424\n",
            "  si: -1.9288\n",
            "  pilot: -1.8777\n",
            "  yr: -1.8264\n",
            "  mechanic: -1.7214\n",
            "  clique: -1.7078\n",
            "  rave: -1.7010\n",
            "  xstp: -1.6550\n",
            "  practical: -1.6402\n",
            "  car: -1.5771\n",
            "  sps: -1.5671\n",
            "  east: -1.5363\n",
            "  snow: -1.5356\n",
            "  october: -1.4929\n",
            "  conservative: -1.4674\n",
            "  diploma: -1.4361\n",
            "  fun: -1.4317\n",
            "  sounds: -1.4279\n",
            "  quality: -1.4034\n",
            "  busy: -1.4029\n",
            "\n",
            "FT dimension:\n",
            "Positive features:\n",
            "  love: 2.5423\n",
            "  sad: 2.4705\n",
            "  feeling: 2.3780\n",
            "  nf: 2.3338\n",
            "  beautiful: 2.1073\n",
            "  idealist: 2.0991\n",
            "  relate: 1.8922\n",
            "  wish: 1.8531\n",
            "  poems: 1.8330\n",
            "  overwhelmed: 1.8180\n",
            "  anxiety: 1.8133\n",
            "  negative: 1.8060\n",
            "  psychic: 1.7983\n",
            "  shyness: 1.7705\n",
            "  world: 1.7596\n",
            "  nfs: 1.7461\n",
            "  daydreaming: 1.7167\n",
            "  sims: 1.7165\n",
            "  idealists: 1.7111\n",
            "  job: 1.7090\n",
            "Negative features:\n",
            "  nt: -2.4672\n",
            "  boring: -2.2612\n",
            "  ti: -2.1881\n",
            "  prove: -2.1002\n",
            "  efficient: -2.0145\n",
            "  win: -1.9714\n",
            "  chess: -1.9202\n",
            "  bored: -1.8919\n",
            "  stupid: -1.8621\n",
            "  fucking: -1.8305\n",
            "  emotions: -1.8101\n",
            "  encyclopedia: -1.7702\n",
            "  chameleon: -1.7551\n",
            "  computer: -1.7542\n",
            "  asks: -1.7143\n",
            "  secondary: -1.7107\n",
            "  illogical: -1.7050\n",
            "  manual: -1.6601\n",
            "  smart: -1.6395\n",
            "  stupidity: -1.6153\n",
            "\n",
            "JP dimension:\n",
            "Positive features:\n",
            "  ni: 5.6093\n",
            "  cold: 2.5866\n",
            "  intuition: 2.4265\n",
            "  bethdeth: 2.2743\n",
            "  applying: 2.2683\n",
            "  jawz: 2.2170\n",
            "  hsp: 2.0909\n",
            "  plans: 2.0523\n",
            "  priorities: 1.9838\n",
            "  understood: 1.9545\n",
            "  efficient: 1.9206\n",
            "  bach: 1.9161\n",
            "  martin: 1.8923\n",
            "  pissed: 1.8817\n",
            "  doorslam: 1.8752\n",
            "  followed: 1.8644\n",
            "  msbossypants: 1.8539\n",
            "  peace: 1.8487\n",
            "  invite: 1.8398\n",
            "  infx: 1.7806\n",
            "Negative features:\n",
            "  ne: -3.5343\n",
            "  established: -2.1231\n",
            "  sunshine: -2.0278\n",
            "  pretty: -1.9555\n",
            "  exciting: -1.9422\n",
            "  zodiac: -1.8093\n",
            "  poe: -1.8060\n",
            "  pills: -1.7749\n",
            "  parents: -1.7562\n",
            "  tried: -1.7395\n",
            "  doubts: -1.7246\n",
            "  fuck: -1.7175\n",
            "  yellow: -1.7110\n",
            "  hike: -1.6787\n",
            "  fi: -1.6491\n",
            "  ahhh: -1.6391\n",
            "  rules: -1.6349\n",
            "  ideas: -1.6001\n",
            "  sadness: -1.5936\n",
            "  daydreaming: -1.5821\n",
            "\n",
            "=== Top features for unigrams_bigrams ===\n",
            "\n",
            "IE dimension:\n",
            "Positive features:\n",
            "  ni: 1.9671\n",
            "  afraid: 1.6369\n",
            "  nature: 1.5913\n",
            "  games: 1.5827\n",
            "  anime: 1.4921\n",
            "  relief: 1.4773\n",
            "  family: 1.4016\n",
            "  circumstances: 1.3850\n",
            "  mind: 1.3337\n",
            "  wish: 1.3210\n",
            "  peaceful: 1.3012\n",
            "  dislike: 1.2813\n",
            "  lyrics: 1.2779\n",
            "  government: 1.2722\n",
            "  just thinking: 1.2488\n",
            "  picky: 1.2457\n",
            "  know need: 1.2382\n",
            "  organize: 1.2380\n",
            "  paranoid: 1.2167\n",
            "  trade: 1.2096\n",
            "Negative features:\n",
            "  ne: -2.4915\n",
            "  dear anonymous: -2.1978\n",
            "  bored: -2.1477\n",
            "  introverted extroverts: -1.7568\n",
            "  ego: -1.6905\n",
            "  fun: -1.6740\n",
            "  excited: -1.6462\n",
            "  que: -1.6319\n",
            "  know guys: -1.5850\n",
            "  just open: -1.5739\n",
            "  bond: -1.5462\n",
            "  mad: -1.5366\n",
            "  boredom: -1.4935\n",
            "  charming: -1.4793\n",
            "  iron: -1.4464\n",
            "  ntp: -1.4429\n",
            "  cheer: -1.4410\n",
            "  distracted: -1.4389\n",
            "  super: -1.4300\n",
            "  hire: -1.4176\n",
            "\n",
            "NS dimension:\n",
            "Positive features:\n",
            "  ideas: 2.0725\n",
            "  dark: 1.9318\n",
            "  nt: 1.9023\n",
            "  world: 1.8323\n",
            "  universe: 1.6859\n",
            "  debate: 1.5709\n",
            "  possibilities: 1.5293\n",
            "  looked: 1.3854\n",
            "  humanity: 1.3841\n",
            "  wasnt: 1.3709\n",
            "  human: 1.3561\n",
            "  past years: 1.3351\n",
            "  intuition: 1.3210\n",
            "  history: 1.2880\n",
            "  cope: 1.2873\n",
            "  likely: 1.2767\n",
            "  nts: 1.2644\n",
            "  nf: 1.2529\n",
            "  ne: 1.2301\n",
            "  tritype: 1.2135\n",
            "Negative features:\n",
            "  rant: -2.9018\n",
            "  si: -2.1252\n",
            "  inferior ne: -1.9530\n",
            "  car: -1.9191\n",
            "  don like: -1.8767\n",
            "  mechanic: -1.8690\n",
            "  rave: -1.8642\n",
            "  yr: -1.8197\n",
            "  martial: -1.5890\n",
            "  fun: -1.5685\n",
            "  xstp: -1.5532\n",
            "  conservative: -1.5503\n",
            "  busy: -1.5323\n",
            "  se ni: -1.5204\n",
            "  sps: -1.5194\n",
            "  snow: -1.5155\n",
            "  east: -1.4800\n",
            "  want hurt: -1.4638\n",
            "  films: -1.4302\n",
            "  practical: -1.3737\n",
            "\n",
            "FT dimension:\n",
            "Positive features:\n",
            "  love: 3.0793\n",
            "  feeling: 2.6872\n",
            "  beautiful: 2.3838\n",
            "  idealist: 2.2680\n",
            "  nf: 2.2500\n",
            "  feel way: 2.2223\n",
            "  ni ti: 2.1728\n",
            "  negative: 2.0858\n",
            "  wish: 2.0790\n",
            "  overwhelmed: 1.9569\n",
            "  relate: 1.9296\n",
            "  sims: 1.9112\n",
            "  anxiety: 1.8661\n",
            "  sorry: 1.8596\n",
            "  kind: 1.8187\n",
            "  idealists: 1.8152\n",
            "  life: 1.8126\n",
            "  writer: 1.7731\n",
            "  nfs: 1.7564\n",
            "  world: 1.7285\n",
            "Negative features:\n",
            "  nt: -3.0963\n",
            "  ti: -2.6477\n",
            "  boring: -2.3930\n",
            "  efficient: -2.3882\n",
            "  inferior fe: -2.1895\n",
            "  win: -2.1643\n",
            "  bored: -2.1149\n",
            "  stupidity: -2.0289\n",
            "  computer: -1.9786\n",
            "  smart: -1.9467\n",
            "  fucking: -1.9302\n",
            "  waste time: -1.9052\n",
            "  asks: -1.8968\n",
            "  illogical: -1.8875\n",
            "  chameleon: -1.8663\n",
            "  efficiency: -1.8487\n",
            "  average: -1.8342\n",
            "  argument: -1.8280\n",
            "  members: -1.8278\n",
            "  prove: -1.8114\n",
            "\n",
            "JP dimension:\n",
            "Positive features:\n",
            "  ni: 6.2592\n",
            "  inferior se: 2.7050\n",
            "  intuition: 2.5646\n",
            "  cold: 2.4512\n",
            "  applying: 2.4341\n",
            "  bethdeth: 2.2547\n",
            "  hsp: 2.2525\n",
            "  jawz: 2.1259\n",
            "  inferior ne: 2.0572\n",
            "  peace: 2.0298\n",
            "  efficient: 2.0200\n",
            "  pissed: 1.9260\n",
            "  bach: 1.8955\n",
            "  doorslam: 1.8034\n",
            "  perfectionist: 1.8019\n",
            "  rave: 1.8013\n",
            "  fe: 1.7741\n",
            "  se fi: 1.7589\n",
            "  think fact: 1.7500\n",
            "  noise: 1.7317\n",
            "Negative features:\n",
            "  ne: -3.7197\n",
            "  inferior fe: -3.1080\n",
            "  se ni: -2.5692\n",
            "  exciting: -2.0045\n",
            "  fi: -1.8508\n",
            "  ideas: -1.8365\n",
            "  buddy: -1.8231\n",
            "  ti: -1.8192\n",
            "  fun: -1.7861\n",
            "  poe: -1.7693\n",
            "  hike: -1.7375\n",
            "  distracted: -1.7320\n",
            "  fuck: -1.7230\n",
            "  pretty sure: -1.7153\n",
            "  ahhh: -1.6955\n",
            "  chaotic: -1.6708\n",
            "  extroverted intuition: -1.6661\n",
            "  parents: -1.6548\n",
            "  isn bad: -1.6478\n",
            "  love: -1.6380\n",
            "\n",
            "=== Top features for all_ngrams ===\n",
            "\n",
            "IE dimension:\n",
            "Positive features:\n",
            "  ni: 1.9532\n",
            "  afraid: 1.5807\n",
            "  nature: 1.5298\n",
            "  family: 1.4700\n",
            "  games: 1.4654\n",
            "  relief: 1.4201\n",
            "  ninja: 1.3484\n",
            "  mind: 1.3457\n",
            "  circumstances: 1.3302\n",
            "  quiet: 1.3258\n",
            "  great deal: 1.3192\n",
            "  anime: 1.3042\n",
            "  trade: 1.2988\n",
            "  organize: 1.2920\n",
            "  government: 1.2919\n",
            "  wish: 1.2854\n",
            "  peaceful: 1.2680\n",
            "  know need: 1.2357\n",
            "  paranoid: 1.2207\n",
            "  spoken: 1.2202\n",
            "Negative features:\n",
            "  ne: -2.5474\n",
            "  bored: -2.2391\n",
            "  dear anonymous: -2.0995\n",
            "  ego: -1.7340\n",
            "  fun: -1.7215\n",
            "  introverted extroverts: -1.6810\n",
            "  mad: -1.6165\n",
            "  charming: -1.5556\n",
            "  excited: -1.5462\n",
            "  hire: -1.5013\n",
            "  universal: -1.4926\n",
            "  bond: -1.4915\n",
            "  distracted: -1.4864\n",
            "  just open: -1.4674\n",
            "  boredom: -1.4642\n",
            "  ntp: -1.4633\n",
            "  know guys: -1.4534\n",
            "  que: -1.4464\n",
            "  cheer: -1.4315\n",
            "  msbossypants: -1.4264\n",
            "\n",
            "NS dimension:\n",
            "Positive features:\n",
            "  ideas: 2.0883\n",
            "  dark: 1.9958\n",
            "  world: 1.9815\n",
            "  nt: 1.9661\n",
            "  universe: 1.6541\n",
            "  debate: 1.4994\n",
            "  humanity: 1.4844\n",
            "  intuition: 1.4713\n",
            "  possibilities: 1.4710\n",
            "  human: 1.4616\n",
            "  writing: 1.4284\n",
            "  books: 1.3540\n",
            "  history: 1.3502\n",
            "  wasnt: 1.3305\n",
            "  nts: 1.2997\n",
            "  patterns: 1.2708\n",
            "  past years: 1.2610\n",
            "  idealist: 1.2572\n",
            "  silly: 1.2414\n",
            "  anxious: 1.2338\n",
            "Negative features:\n",
            "  rant: -3.0015\n",
            "  si: -2.2136\n",
            "  inferior ne: -2.1025\n",
            "  rave: -2.0421\n",
            "  yr: -1.8777\n",
            "  don like: -1.8577\n",
            "  sps: -1.7173\n",
            "  clique: -1.6541\n",
            "  busy: -1.6462\n",
            "  se ni: -1.5515\n",
            "  fun: -1.5182\n",
            "  snow: -1.5089\n",
            "  east: -1.4522\n",
            "  want hurt: -1.4375\n",
            "  practical: -1.3903\n",
            "  diploma: -1.3814\n",
            "  ixtp: -1.3489\n",
            "  films: -1.3438\n",
            "  meepers: -1.3324\n",
            "  october: -1.3313\n",
            "\n",
            "FT dimension:\n",
            "Positive features:\n",
            "  love: 3.4656\n",
            "  feeling: 3.0046\n",
            "  beautiful: 2.6940\n",
            "  idealist: 2.5429\n",
            "  nf: 2.4786\n",
            "  feel way: 2.4281\n",
            "  wish: 2.2802\n",
            "  negative: 2.2193\n",
            "  anxiety: 2.0970\n",
            "  life: 2.0477\n",
            "  idealists: 2.0111\n",
            "  song: 2.0098\n",
            "  writing: 1.9983\n",
            "  sky: 1.9890\n",
            "  overwhelmed: 1.9822\n",
            "  ni ti: 1.9786\n",
            "  relate: 1.9303\n",
            "  fi: 1.9283\n",
            "  sims: 1.9153\n",
            "  ni fe: 1.9002\n",
            "Negative features:\n",
            "  nt: -3.4059\n",
            "  ti: -2.8175\n",
            "  boring: -2.7659\n",
            "  efficient: -2.7608\n",
            "  bored: -2.3126\n",
            "  smart: -2.2800\n",
            "  win: -2.2418\n",
            "  computer: -2.2345\n",
            "  waste time: -2.0735\n",
            "  chameleon: -2.0675\n",
            "  average: -2.0527\n",
            "  fucking: -2.0415\n",
            "  argument: -2.0055\n",
            "  efficiency: -1.9864\n",
            "  inferior fe: -1.9855\n",
            "  asks: -1.9217\n",
            "  point: -1.9121\n",
            "  manual: -1.8280\n",
            "  debate: -1.7558\n",
            "  emotions: -1.7362\n",
            "\n",
            "JP dimension:\n",
            "Positive features:\n",
            "  ni: 6.5836\n",
            "  inferior se: 2.8454\n",
            "  intuition: 2.6454\n",
            "  cold: 2.5508\n",
            "  hsp: 2.3596\n",
            "  bethdeth: 2.2939\n",
            "  jawz: 2.2220\n",
            "  inferior ne: 2.1321\n",
            "  efficient: 2.0464\n",
            "  peace: 1.9576\n",
            "  empathy: 1.8952\n",
            "  bach: 1.8799\n",
            "  quality: 1.8624\n",
            "  se fi: 1.8422\n",
            "  msbossypants: 1.8370\n",
            "  doorslam: 1.8169\n",
            "  dream dream: 1.7892\n",
            "  rave: 1.7773\n",
            "  fe: 1.7687\n",
            "  venting: 1.7284\n",
            "Negative features:\n",
            "  ne: -3.9998\n",
            "  inferior fe: -3.2393\n",
            "  se ni: -2.5166\n",
            "  exciting: -2.0007\n",
            "  fi: -1.9682\n",
            "  pretty sure: -1.9051\n",
            "  fun: -1.8822\n",
            "  ti: -1.8734\n",
            "  buddy: -1.8246\n",
            "  ideas: -1.7756\n",
            "  fuck: -1.7411\n",
            "  hike: -1.7359\n",
            "  chaotic: -1.6784\n",
            "  like talking: -1.6711\n",
            "  poe: -1.6675\n",
            "  imaginary: -1.6530\n",
            "  real world: -1.6409\n",
            "  math: -1.6389\n",
            "  distracted: -1.6284\n",
            "  joker: -1.6013\n",
            "\n",
            "=== Top features for char_ngrams ===\n",
            "\n",
            "IE dimension:\n",
            "Positive features:\n",
            "   ni : 2.1111\n",
            "  yst: 1.7690\n",
            "  ni : 1.7393\n",
            "   ni: 1.6702\n",
            "  iet: 1.4170\n",
            "   se : 1.4149\n",
            "  rad: 1.2078\n",
            "  ian : 1.1890\n",
            "  ian: 1.1267\n",
            "  sign: 1.1127\n",
            "  gam: 1.1083\n",
            "  game: 1.1081\n",
            "  deal: 1.0824\n",
            "   sy: 1.0516\n",
            "  het: 1.0481\n",
            "  orn: 1.0481\n",
            "  nar: 1.0439\n",
            "  eye: 1.0321\n",
            "  ist: 1.0275\n",
            "  ard: 1.0274\n",
            "Negative features:\n",
            "   ne : -3.9786\n",
            "   d : -2.1978\n",
            "   w : -1.9431\n",
            "   bo: -1.9290\n",
            "  fun : -1.5429\n",
            "   bor: -1.5244\n",
            "  ne : -1.5211\n",
            "   fun : -1.5174\n",
            "   ne: -1.4892\n",
            "   ter: -1.4616\n",
            "   te: -1.4428\n",
            "  hot: -1.4050\n",
            "   fl: -1.3563\n",
            "  let: -1.3437\n",
            "  fli: -1.2889\n",
            "   we : -1.2409\n",
            "   an : -1.2377\n",
            "  bus: -1.2146\n",
            "  iness: -1.2107\n",
            "  stu: -1.1961\n",
            "\n",
            "NS dimension:\n",
            "Positive features:\n",
            "   dar: 1.2237\n",
            "   id: 1.1767\n",
            "   al: 1.1393\n",
            "   ide: 1.0960\n",
            "   un: 1.0682\n",
            "  idea: 1.0619\n",
            "   idea: 1.0542\n",
            "  re : 1.0346\n",
            "   ne : 0.9982\n",
            "  eas : 0.9981\n",
            "  so : 0.9638\n",
            "  ppi: 0.9515\n",
            "  man: 0.9457\n",
            "   cor: 0.9454\n",
            "  uit: 0.9428\n",
            "   wai: 0.9381\n",
            "  sci: 0.9316\n",
            "  ora: 0.9201\n",
            "   mis: 0.9144\n",
            "   hm: 0.9006\n",
            "Negative features:\n",
            "   se : -2.1923\n",
            "   ran: -1.7817\n",
            "   se: -1.2385\n",
            "   ra: -1.2179\n",
            "  er : -1.2005\n",
            "  no : -1.1949\n",
            "  rive: -1.1774\n",
            "  ler: -1.1121\n",
            "   sp: -1.0519\n",
            "  ont : -1.0241\n",
            "  sens: -1.0222\n",
            "   fi: -1.0095\n",
            "  lls : -1.0051\n",
            "  ant : -0.9909\n",
            "  fun : -0.9842\n",
            "   fun : -0.9842\n",
            "   ste: -0.9833\n",
            "   st: -0.9809\n",
            "   no : -0.9769\n",
            "  se : -0.9726\n",
            "\n",
            "FT dimension:\n",
            "Positive features:\n",
            "   d : 2.3491\n",
            "  feel : 1.8817\n",
            "   lo: 1.8545\n",
            "   feel: 1.8087\n",
            "   p : 1.7937\n",
            "  feel: 1.7475\n",
            "  spi: 1.7463\n",
            "  eart: 1.7444\n",
            "  sad: 1.7166\n",
            "  el : 1.7081\n",
            "  ful : 1.7072\n",
            "  eel : 1.6994\n",
            "  ul : 1.6880\n",
            "   dee: 1.5866\n",
            "   lov: 1.5377\n",
            "   sad: 1.5320\n",
            "  eel: 1.5092\n",
            "  deal: 1.4952\n",
            "  ues : 1.4865\n",
            "  lov: 1.4781\n",
            "Negative features:\n",
            "   ti : -2.3189\n",
            "  bor: -1.9793\n",
            "   bor: -1.9741\n",
            "   sol: -1.8726\n",
            "   eff: -1.7644\n",
            "   ef: -1.7120\n",
            "   ra: -1.6287\n",
            "  eff: -1.6251\n",
            "  sol: -1.6055\n",
            "  ori: -1.5849\n",
            "   ran: -1.5660\n",
            "   an : -1.5519\n",
            "  ti : -1.5327\n",
            "  nt : -1.5280\n",
            "  olv: -1.5092\n",
            "   pri: -1.4982\n",
            "   pr: -1.4885\n",
            "  ath: -1.4316\n",
            "  aste: -1.4289\n",
            "   ir: -1.4063\n",
            "\n",
            "JP dimension:\n",
            "Positive features:\n",
            "   ni : 6.3294\n",
            "  ni : 5.5352\n",
            "   ni: 2.9561\n",
            "   plan: 1.9574\n",
            "   dea: 1.7283\n",
            "  plan: 1.6831\n",
            "  mas: 1.6652\n",
            "  ition: 1.4896\n",
            "   top: 1.4756\n",
            "   fe : 1.4732\n",
            "  sig: 1.4596\n",
            "  old: 1.3722\n",
            "  gon: 1.3487\n",
            "  itio: 1.3482\n",
            "  rar: 1.2870\n",
            "  oli: 1.2813\n",
            "  ific: 1.2774\n",
            "   ann: 1.2652\n",
            "  ice: 1.2649\n",
            "   pl: 1.2629\n",
            "Negative features:\n",
            "   ne : -4.6434\n",
            "  fi : -2.0002\n",
            "   ti : -1.9746\n",
            "   ne: -1.9290\n",
            "   fi : -1.9268\n",
            "  uck: -1.3614\n",
            "  ril: -1.3534\n",
            "  idea: -1.3037\n",
            "   idea: -1.2953\n",
            "  fuc: -1.2878\n",
            "  cit: -1.2646\n",
            "  oke: -1.2462\n",
            "  ie : -1.2184\n",
            "  non: -1.2180\n",
            "  fuck: -1.2054\n",
            "  free: -1.1966\n",
            "  ti : -1.1964\n",
            "  oke : -1.1950\n",
            "   sm: -1.1731\n",
            "  ame: -1.1586\n"
          ]
        }
      ],
      "source": [
        "# Run the complete evaluation\n",
        "final_results = run_complete_evaluation()\n",
        "\n",
        "# Feature importance analysis\n",
        "def analyze_feature_importance(trained_models, top_n=20):\n",
        "    \"\"\"\n",
        "    Analyze most important features for each MBTI dimension\n",
        "    \"\"\"\n",
        "    for feature_name, model_data in trained_models.items():\n",
        "        print(f\"\\n=== Top features for {feature_name} ===\")\n",
        "        \n",
        "        vectorizer = model_data['vectorizer']\n",
        "        selector = model_data['selector']\n",
        "        model = model_data['model']\n",
        "        \n",
        "        # Get feature names after selection\n",
        "        if selector:\n",
        "            feature_names = vectorizer.get_feature_names_out()[selector.get_support()]\n",
        "        else:\n",
        "            feature_names = vectorizer.get_feature_names_out()\n",
        "        \n",
        "        # Analyze each dimension\n",
        "        for i, dimension in enumerate(['IE', 'NS', 'FT', 'JP']):\n",
        "            print(f\"\\n{dimension} dimension:\")\n",
        "            coef = model.estimators_[i].coef_[0]\n",
        "            \n",
        "            # Get top positive and negative features\n",
        "            top_positive_idx = np.argsort(coef)[-top_n:][::-1]\n",
        "            top_negative_idx = np.argsort(coef)[:top_n]\n",
        "            \n",
        "            print(\"Positive features:\")\n",
        "            for idx in top_positive_idx:\n",
        "                if idx < len(feature_names):\n",
        "                    print(f\"  {feature_names[idx]}: {coef[idx]:.4f}\")\n",
        "            \n",
        "            print(\"Negative features:\")\n",
        "            for idx in top_negative_idx:\n",
        "                if idx < len(feature_names):\n",
        "                    print(f\"  {feature_names[idx]}: {coef[idx]:.4f}\")\n",
        "\n",
        "# Analyze feature importance\n",
        "analyze_feature_importance(final_results['trained_models'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
