{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce6691dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from typing import List, Tuple\n",
    "import os\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7692cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading processed data...\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "print(\"üìÇ Loading processed data...\")\n",
    "train_df = pd.read_pickle('../data/processed/train.pkl')\n",
    "test_df = pd.read_pickle('../data/processed/test.pkl')\n",
    "\n",
    "# Variants\n",
    "variants = [\n",
    "    'without_lemma',\n",
    "    'with_lemma',\n",
    "    'with_lemma_pos',\n",
    "    'with_dep_tree',\n",
    "    'with_chunking'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa935ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare text from tokens/ngrams\n",
    "def prepare_text(tokens: List, ngrams_b: List[Tuple], ngrams_t: List[Tuple], use_ngrams: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Convert tokens and optionally ngrams to string for TF-IDF.\n",
    "    For ngrams, join tuples into space-separated strings.\n",
    "    \"\"\"\n",
    "    if not tokens:\n",
    "        return ''\n",
    "    # Handle different token formats (str or tuples)\n",
    "    if isinstance(tokens[0], str):\n",
    "        text = ' '.join(tokens)\n",
    "    elif isinstance(tokens[0], tuple):\n",
    "        text = ' '.join(['_'.join(t) for t in tokens])\n",
    "    else:\n",
    "        text = ''\n",
    "    \n",
    "    if use_ngrams:\n",
    "        bigrams_str = ' '.join(['_'.join(gram) for gram in ngrams_b]) if ngrams_b else ''\n",
    "        trigrams_str = ' '.join(['_'.join(gram) for gram in ngrams_t]) if ngrams_t else ''\n",
    "        text = f\"{text} {bigrams_str} {trigrams_str}\".strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7213cc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results storage\n",
    "results_multi = {}\n",
    "results_binary = {dim: {} for dim in ['IE', 'NS', 'FT', 'JP']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "263a777b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Processing variant: without_lemma\n",
      "üìù Preparing text features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6940/6940 [00:03<00:00, 2006.97it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1735/1735 [00:00<00:00, 2529.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Training binary model for IE with SMOTE...\n",
      "IE - Accuracy: 0.7447, F1: 0.7522\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.55      0.50       401\n",
      "           1       0.85      0.80      0.83      1334\n",
      "\n",
      "    accuracy                           0.74      1735\n",
      "   macro avg       0.66      0.68      0.66      1735\n",
      "weighted avg       0.76      0.74      0.75      1735\n",
      "\n",
      "üß† Training binary model for NS with SMOTE...\n",
      "NS - Accuracy: 0.8058, F1: 0.8169\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.46      0.40       240\n",
      "           1       0.91      0.86      0.88      1495\n",
      "\n",
      "    accuracy                           0.81      1735\n",
      "   macro avg       0.63      0.66      0.64      1735\n",
      "weighted avg       0.83      0.81      0.82      1735\n",
      "\n",
      "üß† Training binary model for FT with SMOTE...\n",
      "FT - Accuracy: 0.7850, F1: 0.7853\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77       796\n",
      "           1       0.82      0.78      0.80       939\n",
      "\n",
      "    accuracy                           0.79      1735\n",
      "   macro avg       0.78      0.79      0.78      1735\n",
      "weighted avg       0.79      0.79      0.79      1735\n",
      "\n",
      "üß† Training binary model for JP with SMOTE...\n",
      "JP - Accuracy: 0.6640, F1: 0.6656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.70      0.72      1048\n",
      "           1       0.57      0.61      0.59       687\n",
      "\n",
      "    accuracy                           0.66      1735\n",
      "   macro avg       0.65      0.65      0.65      1735\n",
      "weighted avg       0.67      0.66      0.67      1735\n",
      "\n",
      "\n",
      "üîç Processing variant: with_lemma\n",
      "üìù Preparing text features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6940/6940 [00:04<00:00, 1710.19it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1735/1735 [00:01<00:00, 1527.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Training binary model for IE with SMOTE...\n",
      "IE - Accuracy: 0.7372, F1: 0.7460\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.55      0.49       401\n",
      "           1       0.85      0.79      0.82      1334\n",
      "\n",
      "    accuracy                           0.74      1735\n",
      "   macro avg       0.65      0.67      0.66      1735\n",
      "weighted avg       0.76      0.74      0.75      1735\n",
      "\n",
      "üß† Training binary model for NS with SMOTE...\n",
      "NS - Accuracy: 0.8086, F1: 0.8188\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.46      0.40       240\n",
      "           1       0.91      0.86      0.89      1495\n",
      "\n",
      "    accuracy                           0.81      1735\n",
      "   macro avg       0.63      0.66      0.64      1735\n",
      "weighted avg       0.83      0.81      0.82      1735\n",
      "\n",
      "üß† Training binary model for FT with SMOTE...\n",
      "FT - Accuracy: 0.7867, F1: 0.7870\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77       796\n",
      "           1       0.82      0.78      0.80       939\n",
      "\n",
      "    accuracy                           0.79      1735\n",
      "   macro avg       0.79      0.79      0.79      1735\n",
      "weighted avg       0.79      0.79      0.79      1735\n",
      "\n",
      "üß† Training binary model for JP with SMOTE...\n",
      "JP - Accuracy: 0.6622, F1: 0.6639\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.70      0.71      1048\n",
      "           1       0.57      0.61      0.59       687\n",
      "\n",
      "    accuracy                           0.66      1735\n",
      "   macro avg       0.65      0.65      0.65      1735\n",
      "weighted avg       0.67      0.66      0.66      1735\n",
      "\n",
      "\n",
      "üîç Processing variant: with_lemma_pos\n",
      "üìù Preparing text features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6940/6940 [00:04<00:00, 1729.09it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1735/1735 [00:00<00:00, 1756.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Training binary model for IE with SMOTE...\n",
      "IE - Accuracy: 0.7354, F1: 0.7441\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.54      0.48       401\n",
      "           1       0.85      0.79      0.82      1334\n",
      "\n",
      "    accuracy                           0.74      1735\n",
      "   macro avg       0.65      0.67      0.65      1735\n",
      "weighted avg       0.76      0.74      0.74      1735\n",
      "\n",
      "üß† Training binary model for NS with SMOTE...\n",
      "NS - Accuracy: 0.8058, F1: 0.8159\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.45      0.39       240\n",
      "           1       0.91      0.86      0.88      1495\n",
      "\n",
      "    accuracy                           0.81      1735\n",
      "   macro avg       0.63      0.65      0.64      1735\n",
      "weighted avg       0.83      0.81      0.82      1735\n",
      "\n",
      "üß† Training binary model for FT with SMOTE...\n",
      "FT - Accuracy: 0.7781, F1: 0.7784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.79      0.77       796\n",
      "           1       0.81      0.77      0.79       939\n",
      "\n",
      "    accuracy                           0.78      1735\n",
      "   macro avg       0.78      0.78      0.78      1735\n",
      "weighted avg       0.78      0.78      0.78      1735\n",
      "\n",
      "üß† Training binary model for JP with SMOTE...\n",
      "JP - Accuracy: 0.6571, F1: 0.6587\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.69      0.71      1048\n",
      "           1       0.56      0.60      0.58       687\n",
      "\n",
      "    accuracy                           0.66      1735\n",
      "   macro avg       0.64      0.65      0.65      1735\n",
      "weighted avg       0.66      0.66      0.66      1735\n",
      "\n",
      "\n",
      "üîç Processing variant: with_dep_tree\n",
      "üìù Preparing text features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6940/6940 [00:01<00:00, 6631.36it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1735/1735 [00:00<00:00, 12123.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Training binary model for IE with SMOTE...\n",
      "IE - Accuracy: 0.6697, F1: 0.6832\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.43      0.38       401\n",
      "           1       0.81      0.74      0.78      1334\n",
      "\n",
      "    accuracy                           0.67      1735\n",
      "   macro avg       0.57      0.59      0.58      1735\n",
      "weighted avg       0.70      0.67      0.68      1735\n",
      "\n",
      "üß† Training binary model for NS with SMOTE...\n",
      "NS - Accuracy: 0.7228, F1: 0.7486\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.31      0.24       240\n",
      "           1       0.88      0.79      0.83      1495\n",
      "\n",
      "    accuracy                           0.72      1735\n",
      "   macro avg       0.53      0.55      0.53      1735\n",
      "weighted avg       0.78      0.72      0.75      1735\n",
      "\n",
      "üß† Training binary model for FT with SMOTE...\n",
      "FT - Accuracy: 0.6484, F1: 0.6489\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.65      0.63       796\n",
      "           1       0.68      0.65      0.67       939\n",
      "\n",
      "    accuracy                           0.65      1735\n",
      "   macro avg       0.65      0.65      0.65      1735\n",
      "weighted avg       0.65      0.65      0.65      1735\n",
      "\n",
      "üß† Training binary model for JP with SMOTE...\n",
      "JP - Accuracy: 0.5856, F1: 0.5879\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.63      0.65      1048\n",
      "           1       0.48      0.52      0.50       687\n",
      "\n",
      "    accuracy                           0.59      1735\n",
      "   macro avg       0.57      0.57      0.57      1735\n",
      "weighted avg       0.59      0.59      0.59      1735\n",
      "\n",
      "\n",
      "üîç Processing variant: with_chunking\n",
      "üìù Preparing text features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6940/6940 [00:03<00:00, 2129.81it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1735/1735 [00:00<00:00, 2602.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Training binary model for IE with SMOTE...\n",
      "IE - Accuracy: 0.7268, F1: 0.7324\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.47      0.44       401\n",
      "           1       0.84      0.80      0.82      1334\n",
      "\n",
      "    accuracy                           0.73      1735\n",
      "   macro avg       0.63      0.64      0.63      1735\n",
      "weighted avg       0.74      0.73      0.73      1735\n",
      "\n",
      "üß† Training binary model for NS with SMOTE...\n",
      "NS - Accuracy: 0.7758, F1: 0.7883\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.35      0.30       240\n",
      "           1       0.89      0.84      0.87      1495\n",
      "\n",
      "    accuracy                           0.78      1735\n",
      "   macro avg       0.58      0.60      0.58      1735\n",
      "weighted avg       0.80      0.78      0.79      1735\n",
      "\n",
      "üß† Training binary model for FT with SMOTE...\n",
      "FT - Accuracy: 0.7516, F1: 0.7517\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.74      0.73       796\n",
      "           1       0.77      0.76      0.77       939\n",
      "\n",
      "    accuracy                           0.75      1735\n",
      "   macro avg       0.75      0.75      0.75      1735\n",
      "weighted avg       0.75      0.75      0.75      1735\n",
      "\n",
      "üß† Training binary model for JP with SMOTE...\n",
      "JP - Accuracy: 0.6173, F1: 0.6180\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.68      0.68      1048\n",
      "           1       0.52      0.53      0.52       687\n",
      "\n",
      "    accuracy                           0.62      1735\n",
      "   macro avg       0.60      0.60      0.60      1735\n",
      "weighted avg       0.62      0.62      0.62      1735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop over variants\n",
    "for var in variants:\n",
    "    print(f\"\\nüîç Processing variant: {var}\")\n",
    "    \n",
    "    # Prepare train and test texts\n",
    "    print(\"üìù Preparing text features...\")\n",
    "    tqdm.pandas()\n",
    "    train_df['text'] = train_df.progress_apply(\n",
    "        lambda row: prepare_text(row[f'tokens_{var}'], row[f'Bigrams_{var}'], row[f'Trigrams_{var}'], use_ngrams=True), axis=1\n",
    "    )\n",
    "    test_df['text'] = test_df.progress_apply(\n",
    "        lambda row: prepare_text(row[f'tokens_{var}'], row[f'Bigrams_{var}'], row[f'Trigrams_{var}'], use_ngrams=True), axis=1\n",
    "    )\n",
    "    \n",
    "    X_train = train_df['text']\n",
    "    X_test = test_df['text']\n",
    "    \n",
    "    # Multi-class (16 types)\n",
    "    # print(\"üß† Training multi-class model with balanced class weights...\")\n",
    "    # y_train_multi = train_df['type']\n",
    "    # y_test_multi = test_df['type']\n",
    "    \n",
    "    # pipeline_multi = Pipeline([\n",
    "    #     ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1,3))),\n",
    "    #     ('clf', LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, class_weight='balanced'))\n",
    "    # ])\n",
    "    # params = {'clf__C': [0.1, 1, 10], 'clf__solver': ['lbfgs', 'liblinear']}\n",
    "    # grid = GridSearchCV(pipeline_multi, params, cv=5, scoring='f1_weighted')\n",
    "    # grid.fit(X_train, y_train_multi)\n",
    "    \n",
    "    # pipeline_multi.fit(X_train, y_train_multi)\n",
    "    \n",
    "    # y_pred_multi = pipeline_multi.predict(X_test)\n",
    "    \n",
    "    # acc_multi = accuracy_score(y_test_multi, y_pred_multi)\n",
    "    # f1_multi = f1_score(y_test_multi, y_pred_multi, average='weighted')\n",
    "    \n",
    "    # results_multi[var] = {'accuracy': acc_multi, 'f1': f1_multi}\n",
    "    # print(f\"Multi-class - Accuracy: {acc_multi:.4f}, F1: {f1_multi:.4f}\")\n",
    "    # print(classification_report(y_test_multi, y_pred_multi))\n",
    "    \n",
    "    # Save model\n",
    "    # os.makedirs('models', exist_ok=True)\n",
    "    # joblib.dump(pipeline_multi, f'models/multi_{var}.pkl')\n",
    "    \n",
    "    # Binary classifiers for each dimension\n",
    "    for dim in ['IE', 'NS', 'FT', 'JP']:\n",
    "        print(f\"üß† Training binary model for {dim} with SMOTE...\")\n",
    "        y_train_bin = train_df[dim]\n",
    "        y_test_bin = test_df[dim]\n",
    "        \n",
    "        from imblearn.over_sampling import SMOTE\n",
    "        tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,3))\n",
    "        X_train_tfidf = tfidf.fit_transform(X_train).toarray()\n",
    "        X_test_tfidf = tfidf.transform(X_test).toarray()  \n",
    "        \n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_res, y_train_res = smote.fit_resample(X_train_tfidf, y_train_bin)\n",
    "        \n",
    "        clf = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "        clf.fit(X_train_res, y_train_res)\n",
    "        y_pred_bin = clf.predict(X_test_tfidf)\n",
    "        \n",
    "        acc_bin = accuracy_score(y_test_bin, y_pred_bin)\n",
    "        f1_bin = f1_score(y_test_bin, y_pred_bin, average='weighted')\n",
    "        \n",
    "        results_binary[dim][var] = {'accuracy': acc_bin, 'f1': f1_bin}\n",
    "        print(f\"{dim} - Accuracy: {acc_bin:.4f}, F1: {f1_bin:.4f}\")\n",
    "        print(classification_report(y_test_bin, y_pred_bin))\n",
    "    \n",
    "        joblib.dump((tfidf, clf), f'../models/binary_{dim}_{var}.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f3f01ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading processed data...\n",
      "\n",
      "üîç Processing variant: without_lemma for balanced test eval\n",
      "üìù Preparing text features for test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1735/1735 [00:00<00:00, 4944.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öñÔ∏è Loading model and evaluating IE on SMOTE-balanced test...\n",
      "IE - Accuracy (on SMOTE-balanced test): 0.7148, F1: 0.7125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.63      0.69      1334\n",
      "           1       0.68      0.80      0.74      1334\n",
      "\n",
      "    accuracy                           0.71      2668\n",
      "   macro avg       0.72      0.71      0.71      2668\n",
      "weighted avg       0.72      0.71      0.71      2668\n",
      "\n",
      "‚öñÔ∏è Loading model and evaluating NS on SMOTE-balanced test...\n",
      "NS - Accuracy (on SMOTE-balanced test): 0.6729, F1: 0.6609\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.48      0.60      1495\n",
      "           1       0.63      0.86      0.72      1495\n",
      "\n",
      "    accuracy                           0.67      2990\n",
      "   macro avg       0.70      0.67      0.66      2990\n",
      "weighted avg       0.70      0.67      0.66      2990\n",
      "\n",
      "‚öñÔ∏è Loading model and evaluating FT on SMOTE-balanced test...\n",
      "FT - Accuracy (on SMOTE-balanced test): 0.7881, F1: 0.7881\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79       939\n",
      "           1       0.79      0.78      0.79       939\n",
      "\n",
      "    accuracy                           0.79      1878\n",
      "   macro avg       0.79      0.79      0.79      1878\n",
      "weighted avg       0.79      0.79      0.79      1878\n",
      "\n",
      "‚öñÔ∏è Loading model and evaluating JP on SMOTE-balanced test...\n",
      "JP - Accuracy (on SMOTE-balanced test): 0.6570, F1: 0.6563\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.70      0.67      1048\n",
      "           1       0.67      0.61      0.64      1048\n",
      "\n",
      "    accuracy                           0.66      2096\n",
      "   macro avg       0.66      0.66      0.66      2096\n",
      "weighted avg       0.66      0.66      0.66      2096\n",
      "\n",
      "\n",
      "üîç Processing variant: with_lemma for balanced test eval\n",
      "üìù Preparing text features for test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1735/1735 [00:00<00:00, 3638.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öñÔ∏è Loading model and evaluating IE on SMOTE-balanced test...\n",
      "IE - Accuracy (on SMOTE-balanced test): 0.7009, F1: 0.6983\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.61      0.67      1334\n",
      "           1       0.67      0.79      0.73      1334\n",
      "\n",
      "    accuracy                           0.70      2668\n",
      "   macro avg       0.71      0.70      0.70      2668\n",
      "weighted avg       0.71      0.70      0.70      2668\n",
      "\n",
      "‚öñÔ∏è Loading model and evaluating NS on SMOTE-balanced test...\n",
      "NS - Accuracy (on SMOTE-balanced test): 0.6736, F1: 0.6612\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.48      0.60      1495\n",
      "           1       0.63      0.86      0.73      1495\n",
      "\n",
      "    accuracy                           0.67      2990\n",
      "   macro avg       0.70      0.67      0.66      2990\n",
      "weighted avg       0.70      0.67      0.66      2990\n",
      "\n",
      "‚öñÔ∏è Loading model and evaluating FT on SMOTE-balanced test...\n",
      "FT - Accuracy (on SMOTE-balanced test): 0.7881, F1: 0.7881\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79       939\n",
      "           1       0.79      0.78      0.79       939\n",
      "\n",
      "    accuracy                           0.79      1878\n",
      "   macro avg       0.79      0.79      0.79      1878\n",
      "weighted avg       0.79      0.79      0.79      1878\n",
      "\n",
      "‚öñÔ∏è Loading model and evaluating JP on SMOTE-balanced test...\n",
      "JP - Accuracy (on SMOTE-balanced test): 0.6579, F1: 0.6574\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.70      0.67      1048\n",
      "           1       0.67      0.62      0.64      1048\n",
      "\n",
      "    accuracy                           0.66      2096\n",
      "   macro avg       0.66      0.66      0.66      2096\n",
      "weighted avg       0.66      0.66      0.66      2096\n",
      "\n",
      "\n",
      "üîç Processing variant: with_lemma_pos for balanced test eval\n",
      "üìù Preparing text features for test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1735/1735 [00:00<00:00, 4155.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öñÔ∏è Loading model and evaluating IE on SMOTE-balanced test...\n",
      "IE - Accuracy (on SMOTE-balanced test): 0.6979, F1: 0.6950\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.60      0.67      1334\n",
      "           1       0.67      0.79      0.72      1334\n",
      "\n",
      "    accuracy                           0.70      2668\n",
      "   macro avg       0.71      0.70      0.70      2668\n",
      "weighted avg       0.71      0.70      0.70      2668\n",
      "\n",
      "‚öñÔ∏è Loading model and evaluating NS on SMOTE-balanced test...\n",
      "NS - Accuracy (on SMOTE-balanced test): 0.6856, F1: 0.6753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.51      0.62      1495\n",
      "           1       0.64      0.86      0.73      1495\n",
      "\n",
      "    accuracy                           0.69      2990\n",
      "   macro avg       0.71      0.69      0.68      2990\n",
      "weighted avg       0.71      0.69      0.68      2990\n",
      "\n",
      "‚öñÔ∏è Loading model and evaluating FT on SMOTE-balanced test...\n",
      "FT - Accuracy (on SMOTE-balanced test): 0.7801, F1: 0.7801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78       939\n",
      "           1       0.79      0.77      0.78       939\n",
      "\n",
      "    accuracy                           0.78      1878\n",
      "   macro avg       0.78      0.78      0.78      1878\n",
      "weighted avg       0.78      0.78      0.78      1878\n",
      "\n",
      "‚öñÔ∏è Loading model and evaluating JP on SMOTE-balanced test...\n",
      "JP - Accuracy (on SMOTE-balanced test): 0.6594, F1: 0.6589\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.69      0.67      1048\n",
      "           1       0.67      0.62      0.65      1048\n",
      "\n",
      "    accuracy                           0.66      2096\n",
      "   macro avg       0.66      0.66      0.66      2096\n",
      "weighted avg       0.66      0.66      0.66      2096\n",
      "\n",
      "\n",
      "üîç Processing variant: with_dep_tree for balanced test eval\n",
      "üìù Preparing text features for test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1735/1735 [00:00<00:00, 22380.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öñÔ∏è Loading model and evaluating IE on SMOTE-balanced test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IE - Accuracy (on SMOTE-balanced test): 0.6192, F1: 0.6134\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.50      0.57      1334\n",
      "           1       0.60      0.74      0.66      1334\n",
      "\n",
      "    accuracy                           0.62      2668\n",
      "   macro avg       0.63      0.62      0.61      2668\n",
      "weighted avg       0.63      0.62      0.61      2668\n",
      "\n",
      "‚öñÔ∏è Loading model and evaluating NS on SMOTE-balanced test...\n",
      "NS - Accuracy (on SMOTE-balanced test): 0.5666, F1: 0.5441\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.34      0.44      1495\n",
      "           1       0.55      0.79      0.65      1495\n",
      "\n",
      "    accuracy                           0.57      2990\n",
      "   macro avg       0.58      0.57      0.54      2990\n",
      "weighted avg       0.58      0.57      0.54      2990\n",
      "\n",
      "‚öñÔ∏è Loading model and evaluating FT on SMOTE-balanced test...\n",
      "FT - Accuracy (on SMOTE-balanced test): 0.6544, F1: 0.6544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.66      0.66       939\n",
      "           1       0.66      0.65      0.65       939\n",
      "\n",
      "    accuracy                           0.65      1878\n",
      "   macro avg       0.65      0.65      0.65      1878\n",
      "weighted avg       0.65      0.65      0.65      1878\n",
      "\n",
      "‚öñÔ∏è Loading model and evaluating JP on SMOTE-balanced test...\n",
      "JP - Accuracy (on SMOTE-balanced test): 0.5596, F1: 0.5573\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.63      0.59      1048\n",
      "           1       0.57      0.49      0.53      1048\n",
      "\n",
      "    accuracy                           0.56      2096\n",
      "   macro avg       0.56      0.56      0.56      2096\n",
      "weighted avg       0.56      0.56      0.56      2096\n",
      "\n",
      "\n",
      "üîç Processing variant: with_chunking for balanced test eval\n",
      "üìù Preparing text features for test...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1735/1735 [00:00<00:00, 4054.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öñÔ∏è Loading model and evaluating IE on SMOTE-balanced test...\n",
      "IE - Accuracy (on SMOTE-balanced test): 0.6675, F1: 0.6613\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.53      0.62      1334\n",
      "           1       0.63      0.80      0.71      1334\n",
      "\n",
      "    accuracy                           0.67      2668\n",
      "   macro avg       0.68      0.67      0.66      2668\n",
      "weighted avg       0.68      0.67      0.66      2668\n",
      "\n",
      "‚öñÔ∏è Loading model and evaluating NS on SMOTE-balanced test...\n",
      "NS - Accuracy (on SMOTE-balanced test): 0.6579, F1: 0.6456\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.47      0.58      1495\n",
      "           1       0.62      0.84      0.71      1495\n",
      "\n",
      "    accuracy                           0.66      2990\n",
      "   macro avg       0.68      0.66      0.65      2990\n",
      "weighted avg       0.68      0.66      0.65      2990\n",
      "\n",
      "‚öñÔ∏è Loading model and evaluating FT on SMOTE-balanced test...\n",
      "FT - Accuracy (on SMOTE-balanced test): 0.7583, F1: 0.7582\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.76       939\n",
      "           1       0.76      0.76      0.76       939\n",
      "\n",
      "    accuracy                           0.76      1878\n",
      "   macro avg       0.76      0.76      0.76      1878\n",
      "weighted avg       0.76      0.76      0.76      1878\n",
      "\n",
      "‚öñÔ∏è Loading model and evaluating JP on SMOTE-balanced test...\n",
      "JP - Accuracy (on SMOTE-balanced test): 0.6307, F1: 0.6300\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.68      0.65      1048\n",
      "           1       0.64      0.59      0.61      1048\n",
      "\n",
      "    accuracy                           0.63      2096\n",
      "   macro avg       0.63      0.63      0.63      2096\n",
      "weighted avg       0.63      0.63      0.63      2096\n",
      "\n",
      "\n",
      "üìä Comparison of Binary IE Results on Balanced Test:\n",
      "without_lemma: Accuracy=0.7148, F1=0.7125\n",
      "with_lemma: Accuracy=0.7009, F1=0.6983\n",
      "with_lemma_pos: Accuracy=0.6979, F1=0.6950\n",
      "with_dep_tree: Accuracy=0.6192, F1=0.6134\n",
      "with_chunking: Accuracy=0.6675, F1=0.6613\n",
      "\n",
      "üìä Comparison of Binary NS Results on Balanced Test:\n",
      "without_lemma: Accuracy=0.6729, F1=0.6609\n",
      "with_lemma: Accuracy=0.6736, F1=0.6612\n",
      "with_lemma_pos: Accuracy=0.6856, F1=0.6753\n",
      "with_dep_tree: Accuracy=0.5666, F1=0.5441\n",
      "with_chunking: Accuracy=0.6579, F1=0.6456\n",
      "\n",
      "üìä Comparison of Binary FT Results on Balanced Test:\n",
      "without_lemma: Accuracy=0.7881, F1=0.7881\n",
      "with_lemma: Accuracy=0.7881, F1=0.7881\n",
      "with_lemma_pos: Accuracy=0.7801, F1=0.7801\n",
      "with_dep_tree: Accuracy=0.6544, F1=0.6544\n",
      "with_chunking: Accuracy=0.7583, F1=0.7582\n",
      "\n",
      "üìä Comparison of Binary JP Results on Balanced Test:\n",
      "without_lemma: Accuracy=0.6570, F1=0.6563\n",
      "with_lemma: Accuracy=0.6579, F1=0.6574\n",
      "with_lemma_pos: Accuracy=0.6594, F1=0.6589\n",
      "with_dep_tree: Accuracy=0.5596, F1=0.5573\n",
      "with_chunking: Accuracy=0.6307, F1=0.6300\n",
      "‚úÖ Balanced test evaluation complete!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"üìÇ Loading processed data...\")\n",
    "train_df = pd.read_pickle('../data/processed/train.pkl')\n",
    "test_df = pd.read_pickle('../data/processed/test.pkl')\n",
    "\n",
    "# Variants (same as before)\n",
    "variants = [\n",
    "    'without_lemma',\n",
    "    'with_lemma',\n",
    "    'with_lemma_pos',\n",
    "    'with_dep_tree',\n",
    "    'with_chunking'\n",
    "]\n",
    "\n",
    "# Results storage for balanced test eval\n",
    "results_binary_balanced = {dim: {} for dim in ['IE', 'NS', 'FT', 'JP']}\n",
    "\n",
    "# Loop over variants\n",
    "for var in variants:\n",
    "    print(f\"\\nüîç Processing variant: {var} for balanced test eval\")\n",
    "    \n",
    "    # Prepare test texts (same as in training)\n",
    "    print(\"üìù Preparing text features for test...\")\n",
    "    tqdm.pandas()\n",
    "    test_df['text'] = test_df.progress_apply(\n",
    "        lambda row: prepare_text(row[f'tokens_{var}'], row[f'Bigrams_{var}'], row[f'Trigrams_{var}'], use_ngrams=True), axis=1\n",
    "    )\n",
    "    X_test = test_df['text']\n",
    "    \n",
    "    # Binary dimensions\n",
    "    for dim in ['IE', 'NS', 'FT', 'JP']:\n",
    "        print(f\"‚öñÔ∏è Loading model and evaluating {dim} on SMOTE-balanced test...\")\n",
    "        y_test_bin = test_df[dim]\n",
    "        \n",
    "        # Load the saved tfidf and clf\n",
    "        model_path = f'../models/binary_{dim}_{var}.pkl'\n",
    "        tfidf, clf = joblib.load(model_path)\n",
    "        \n",
    "        # Vectorize test (dense for SMOTE)\n",
    "        X_test_tfidf = tfidf.transform(X_test).toarray()\n",
    "        \n",
    "        # Apply SMOTE to test data\n",
    "        smote_test = SMOTE(random_state=42)\n",
    "        X_test_res, y_test_res = smote_test.fit_resample(X_test_tfidf, y_test_bin)\n",
    "        \n",
    "        # Predict on balanced test\n",
    "        y_pred_bin = clf.predict(X_test_res)\n",
    "        \n",
    "        acc_bin = accuracy_score(y_test_res, y_pred_bin)\n",
    "        f1_bin = f1_score(y_test_res, y_pred_bin, average='weighted')\n",
    "        \n",
    "        results_binary_balanced[dim][var] = {'accuracy': acc_bin, 'f1': f1_bin}\n",
    "        print(f\"{dim} - Accuracy (on SMOTE-balanced test): {acc_bin:.4f}, F1: {f1_bin:.4f}\")\n",
    "        print(classification_report(y_test_res, y_pred_bin))\n",
    "\n",
    "# Compare results for balanced test\n",
    "for dim in ['IE', 'NS', 'FT', 'JP']:\n",
    "    print(f\"\\nüìä Comparison of Binary {dim} Results on Balanced Test:\")\n",
    "    for var, res in results_binary_balanced[dim].items():\n",
    "        print(f\"{var}: Accuracy={res['accuracy']:.4f}, F1={res['f1']:.4f}\")\n",
    "\n",
    "print(\"‚úÖ Balanced test evaluation complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_miniproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
