{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce6691dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from typing import List, Tuple\n",
    "import os\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7692cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading processed data...\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "print(\"üìÇ Loading processed data...\")\n",
    "train_df = pd.read_pickle('../data/processed/train.pkl')\n",
    "test_df = pd.read_pickle('../data/processed/test.pkl')\n",
    "\n",
    "# Variants\n",
    "variants = [\n",
    "    'without_lemma',\n",
    "    'with_lemma',\n",
    "    'with_lemma_pos',\n",
    "    'with_dep_tree',\n",
    "    'with_chunking'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa935ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare text from tokens/ngrams\n",
    "def prepare_text(tokens: List, ngrams_b: List[Tuple], ngrams_t: List[Tuple], use_ngrams: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Convert tokens and optionally ngrams to string for TF-IDF.\n",
    "    For ngrams, join tuples into space-separated strings.\n",
    "    \"\"\"\n",
    "    if not tokens:\n",
    "        return ''\n",
    "    # Handle different token formats (str or tuples)\n",
    "    if isinstance(tokens[0], str):\n",
    "        text = ' '.join(tokens)\n",
    "    elif isinstance(tokens[0], tuple):\n",
    "        text = ' '.join(['_'.join(t) for t in tokens])\n",
    "    else:\n",
    "        text = ''\n",
    "    \n",
    "    if use_ngrams:\n",
    "        bigrams_str = ' '.join(['_'.join(gram) for gram in ngrams_b]) if ngrams_b else ''\n",
    "        trigrams_str = ' '.join(['_'.join(gram) for gram in ngrams_t]) if ngrams_t else ''\n",
    "        text = f\"{text} {bigrams_str} {trigrams_str}\".strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7213cc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results storage\n",
    "results_multi = {}\n",
    "results_binary = {dim: {} for dim in ['IE', 'NS', 'FT', 'JP']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "263a777b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Processing variant: without_lemma\n",
      "üìù Preparing text features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6940/6940 [00:03<00:00, 2099.35it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1735/1735 [00:00<00:00, 2654.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Training multi-class model with balanced class weights...\n",
      "Multi-class - Accuracy: 0.3527, F1: 0.3671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.14      0.32      0.19        38\n",
      "        ENFP       0.35      0.40      0.37       135\n",
      "        ENTJ       0.10      0.24      0.14        46\n",
      "        ENTP       0.38      0.39      0.38       137\n",
      "        ESFJ       0.00      0.00      0.00         9\n",
      "        ESFP       0.00      0.00      0.00        10\n",
      "        ESTJ       0.00      0.00      0.00         8\n",
      "        ESTP       0.04      0.06      0.05        18\n",
      "        INFJ       0.48      0.26      0.34       294\n",
      "        INFP       0.56      0.45      0.50       366\n",
      "        INTJ       0.37      0.30      0.33       218\n",
      "        INTP       0.50      0.41      0.45       261\n",
      "        ISFJ       0.17      0.36      0.23        33\n",
      "        ISFP       0.17      0.31      0.22        54\n",
      "        ISTJ       0.14      0.20      0.16        41\n",
      "        ISTP       0.26      0.45      0.33        67\n",
      "\n",
      "    accuracy                           0.35      1735\n",
      "   macro avg       0.23      0.26      0.23      1735\n",
      "weighted avg       0.40      0.35      0.37      1735\n",
      "\n",
      "üß† Training binary model for IE with balanced class weights...\n",
      "IE - Accuracy: 0.7308, F1: 0.7447\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.62      0.52       401\n",
      "           1       0.87      0.76      0.81      1334\n",
      "\n",
      "    accuracy                           0.73      1735\n",
      "   macro avg       0.66      0.69      0.66      1735\n",
      "weighted avg       0.77      0.73      0.74      1735\n",
      "\n",
      "üß† Training binary model for NS with balanced class weights...\n",
      "NS - Accuracy: 0.7856, F1: 0.8067\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.57      0.42       240\n",
      "           1       0.92      0.82      0.87      1495\n",
      "\n",
      "    accuracy                           0.79      1735\n",
      "   macro avg       0.63      0.69      0.65      1735\n",
      "weighted avg       0.84      0.79      0.81      1735\n",
      "\n",
      "üß† Training binary model for FT with balanced class weights...\n",
      "FT - Accuracy: 0.7821, F1: 0.7824\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77       796\n",
      "           1       0.81      0.78      0.79       939\n",
      "\n",
      "    accuracy                           0.78      1735\n",
      "   macro avg       0.78      0.78      0.78      1735\n",
      "weighted avg       0.78      0.78      0.78      1735\n",
      "\n",
      "üß† Training binary model for JP with balanced class weights...\n",
      "JP - Accuracy: 0.6663, F1: 0.6689\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.68      0.71      1048\n",
      "           1       0.57      0.64      0.60       687\n",
      "\n",
      "    accuracy                           0.67      1735\n",
      "   macro avg       0.66      0.66      0.66      1735\n",
      "weighted avg       0.67      0.67      0.67      1735\n",
      "\n",
      "\n",
      "üîç Processing variant: with_lemma\n",
      "üìù Preparing text features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6940/6940 [00:04<00:00, 1599.78it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1735/1735 [00:00<00:00, 2026.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Training multi-class model with balanced class weights...\n",
      "Multi-class - Accuracy: 0.3470, F1: 0.3608\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.12      0.26      0.17        38\n",
      "        ENFP       0.33      0.38      0.35       135\n",
      "        ENTJ       0.12      0.26      0.17        46\n",
      "        ENTP       0.35      0.39      0.37       137\n",
      "        ESFJ       0.00      0.00      0.00         9\n",
      "        ESFP       0.00      0.00      0.00        10\n",
      "        ESTJ       0.00      0.00      0.00         8\n",
      "        ESTP       0.04      0.06      0.05        18\n",
      "        INFJ       0.49      0.25      0.33       294\n",
      "        INFP       0.56      0.46      0.50       366\n",
      "        INTJ       0.35      0.27      0.30       218\n",
      "        INTP       0.49      0.41      0.45       261\n",
      "        ISFJ       0.13      0.24      0.17        33\n",
      "        ISFP       0.14      0.28      0.18        54\n",
      "        ISTJ       0.15      0.22      0.18        41\n",
      "        ISTP       0.29      0.51      0.37        67\n",
      "\n",
      "    accuracy                           0.35      1735\n",
      "   macro avg       0.22      0.25      0.22      1735\n",
      "weighted avg       0.40      0.35      0.36      1735\n",
      "\n",
      "üß† Training binary model for IE with balanced class weights...\n",
      "IE - Accuracy: 0.7297, F1: 0.7436\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.62      0.51       401\n",
      "           1       0.87      0.76      0.81      1334\n",
      "\n",
      "    accuracy                           0.73      1735\n",
      "   macro avg       0.65      0.69      0.66      1735\n",
      "weighted avg       0.77      0.73      0.74      1735\n",
      "\n",
      "üß† Training binary model for NS with balanced class weights...\n",
      "NS - Accuracy: 0.7844, F1: 0.8053\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.55      0.42       240\n",
      "           1       0.92      0.82      0.87      1495\n",
      "\n",
      "    accuracy                           0.78      1735\n",
      "   macro avg       0.63      0.69      0.64      1735\n",
      "weighted avg       0.84      0.78      0.81      1735\n",
      "\n",
      "üß† Training binary model for FT with balanced class weights...\n",
      "FT - Accuracy: 0.7879, F1: 0.7882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.80      0.78       796\n",
      "           1       0.82      0.78      0.80       939\n",
      "\n",
      "    accuracy                           0.79      1735\n",
      "   macro avg       0.79      0.79      0.79      1735\n",
      "weighted avg       0.79      0.79      0.79      1735\n",
      "\n",
      "üß† Training binary model for JP with balanced class weights...\n",
      "JP - Accuracy: 0.6692, F1: 0.6719\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.68      0.71      1048\n",
      "           1       0.57      0.65      0.61       687\n",
      "\n",
      "    accuracy                           0.67      1735\n",
      "   macro avg       0.66      0.67      0.66      1735\n",
      "weighted avg       0.68      0.67      0.67      1735\n",
      "\n",
      "\n",
      "üîç Processing variant: with_lemma_pos\n",
      "üìù Preparing text features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6940/6940 [00:04<00:00, 1591.30it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1735/1735 [00:00<00:00, 1913.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Training multi-class model with balanced class weights...\n",
      "Multi-class - Accuracy: 0.3412, F1: 0.3572\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.10      0.21      0.14        38\n",
      "        ENFP       0.29      0.35      0.32       135\n",
      "        ENTJ       0.11      0.26      0.15        46\n",
      "        ENTP       0.37      0.39      0.38       137\n",
      "        ESFJ       0.00      0.00      0.00         9\n",
      "        ESFP       0.00      0.00      0.00        10\n",
      "        ESTJ       0.00      0.00      0.00         8\n",
      "        ESTP       0.04      0.06      0.05        18\n",
      "        INFJ       0.50      0.27      0.35       294\n",
      "        INFP       0.54      0.43      0.48       366\n",
      "        INTJ       0.35      0.29      0.32       218\n",
      "        INTP       0.49      0.40      0.44       261\n",
      "        ISFJ       0.12      0.24      0.16        33\n",
      "        ISFP       0.15      0.30      0.20        54\n",
      "        ISTJ       0.18      0.27      0.22        41\n",
      "        ISTP       0.26      0.46      0.34        67\n",
      "\n",
      "    accuracy                           0.34      1735\n",
      "   macro avg       0.22      0.25      0.22      1735\n",
      "weighted avg       0.40      0.34      0.36      1735\n",
      "\n",
      "üß† Training binary model for IE with balanced class weights...\n",
      "IE - Accuracy: 0.7222, F1: 0.7368\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.61      0.50       401\n",
      "           1       0.86      0.76      0.81      1334\n",
      "\n",
      "    accuracy                           0.72      1735\n",
      "   macro avg       0.65      0.68      0.65      1735\n",
      "weighted avg       0.76      0.72      0.74      1735\n",
      "\n",
      "üß† Training binary model for NS with balanced class weights...\n",
      "NS - Accuracy: 0.7850, F1: 0.8061\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.56      0.42       240\n",
      "           1       0.92      0.82      0.87      1495\n",
      "\n",
      "    accuracy                           0.79      1735\n",
      "   macro avg       0.63      0.69      0.64      1735\n",
      "weighted avg       0.84      0.79      0.81      1735\n",
      "\n",
      "üß† Training binary model for FT with balanced class weights...\n",
      "FT - Accuracy: 0.7775, F1: 0.7779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.79      0.77       796\n",
      "           1       0.81      0.76      0.79       939\n",
      "\n",
      "    accuracy                           0.78      1735\n",
      "   macro avg       0.78      0.78      0.78      1735\n",
      "weighted avg       0.78      0.78      0.78      1735\n",
      "\n",
      "üß† Training binary model for JP with balanced class weights...\n",
      "JP - Accuracy: 0.6622, F1: 0.6649\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.68      0.71      1048\n",
      "           1       0.57      0.63      0.60       687\n",
      "\n",
      "    accuracy                           0.66      1735\n",
      "   macro avg       0.65      0.66      0.65      1735\n",
      "weighted avg       0.67      0.66      0.66      1735\n",
      "\n",
      "\n",
      "üîç Processing variant: with_dep_tree\n",
      "üìù Preparing text features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6940/6940 [00:01<00:00, 5564.05it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1735/1735 [00:00<00:00, 5677.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Training multi-class model with balanced class weights...\n",
      "Multi-class - Accuracy: 0.1516, F1: 0.1692\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.04      0.11      0.05        38\n",
      "        ENFP       0.19      0.24      0.21       135\n",
      "        ENTJ       0.04      0.13      0.06        46\n",
      "        ENTP       0.18      0.18      0.18       137\n",
      "        ESFJ       0.08      0.11      0.09         9\n",
      "        ESFP       0.04      0.10      0.06        10\n",
      "        ESTJ       0.00      0.00      0.00         8\n",
      "        ESTP       0.00      0.00      0.00        18\n",
      "        INFJ       0.28      0.13      0.17       294\n",
      "        INFP       0.34      0.16      0.22       366\n",
      "        INTJ       0.23      0.14      0.17       218\n",
      "        INTP       0.26      0.13      0.18       261\n",
      "        ISFJ       0.04      0.12      0.06        33\n",
      "        ISFP       0.07      0.20      0.11        54\n",
      "        ISTJ       0.05      0.12      0.07        41\n",
      "        ISTP       0.09      0.18      0.12        67\n",
      "\n",
      "    accuracy                           0.15      1735\n",
      "   macro avg       0.12      0.13      0.11      1735\n",
      "weighted avg       0.23      0.15      0.17      1735\n",
      "\n",
      "üß† Training binary model for IE with balanced class weights...\n",
      "IE - Accuracy: 0.6571, F1: 0.6775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.51      0.41       401\n",
      "           1       0.83      0.70      0.76      1334\n",
      "\n",
      "    accuracy                           0.66      1735\n",
      "   macro avg       0.58      0.61      0.58      1735\n",
      "weighted avg       0.71      0.66      0.68      1735\n",
      "\n",
      "üß† Training binary model for NS with balanced class weights...\n",
      "NS - Accuracy: 0.6928, F1: 0.7291\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.35      0.24       240\n",
      "           1       0.88      0.75      0.81      1495\n",
      "\n",
      "    accuracy                           0.69      1735\n",
      "   macro avg       0.53      0.55      0.52      1735\n",
      "weighted avg       0.78      0.69      0.73      1735\n",
      "\n",
      "üß† Training binary model for FT with balanced class weights...\n",
      "FT - Accuracy: 0.6496, F1: 0.6501\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.65      0.63       796\n",
      "           1       0.69      0.65      0.67       939\n",
      "\n",
      "    accuracy                           0.65      1735\n",
      "   macro avg       0.65      0.65      0.65      1735\n",
      "weighted avg       0.65      0.65      0.65      1735\n",
      "\n",
      "üß† Training binary model for JP with balanced class weights...\n",
      "JP - Accuracy: 0.5775, F1: 0.5816\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.60      0.63      1048\n",
      "           1       0.47      0.55      0.51       687\n",
      "\n",
      "    accuracy                           0.58      1735\n",
      "   macro avg       0.57      0.57      0.57      1735\n",
      "weighted avg       0.59      0.58      0.58      1735\n",
      "\n",
      "\n",
      "üîç Processing variant: with_chunking\n",
      "üìù Preparing text features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6940/6940 [00:03<00:00, 2214.07it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1735/1735 [00:00<00:00, 2331.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Training multi-class model with balanced class weights...\n",
      "Multi-class - Accuracy: 0.2767, F1: 0.2926\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.08      0.21      0.12        38\n",
      "        ENFP       0.28      0.33      0.30       135\n",
      "        ENTJ       0.10      0.30      0.16        46\n",
      "        ENTP       0.31      0.28      0.29       137\n",
      "        ESFJ       0.05      0.11      0.06         9\n",
      "        ESFP       0.05      0.10      0.07        10\n",
      "        ESTJ       0.00      0.00      0.00         8\n",
      "        ESTP       0.00      0.00      0.00        18\n",
      "        INFJ       0.37      0.19      0.25       294\n",
      "        INFP       0.48      0.34      0.39       366\n",
      "        INTJ       0.28      0.20      0.24       218\n",
      "        INTP       0.45      0.35      0.39       261\n",
      "        ISFJ       0.11      0.27      0.16        33\n",
      "        ISFP       0.12      0.24      0.16        54\n",
      "        ISTJ       0.14      0.22      0.17        41\n",
      "        ISTP       0.23      0.40      0.30        67\n",
      "\n",
      "    accuracy                           0.28      1735\n",
      "   macro avg       0.19      0.22      0.19      1735\n",
      "weighted avg       0.34      0.28      0.29      1735\n",
      "\n",
      "üß† Training binary model for IE with balanced class weights...\n",
      "IE - Accuracy: 0.7037, F1: 0.7196\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.57      0.47       401\n",
      "           1       0.85      0.74      0.79      1334\n",
      "\n",
      "    accuracy                           0.70      1735\n",
      "   macro avg       0.63      0.66      0.63      1735\n",
      "weighted avg       0.75      0.70      0.72      1735\n",
      "\n",
      "üß† Training binary model for NS with balanced class weights...\n",
      "NS - Accuracy: 0.7556, F1: 0.7813\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.50      0.36       240\n",
      "           1       0.91      0.80      0.85      1495\n",
      "\n",
      "    accuracy                           0.76      1735\n",
      "   macro avg       0.59      0.65      0.60      1735\n",
      "weighted avg       0.82      0.76      0.78      1735\n",
      "\n",
      "üß† Training binary model for FT with balanced class weights...\n",
      "FT - Accuracy: 0.7487, F1: 0.7490\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       796\n",
      "           1       0.78      0.75      0.76       939\n",
      "\n",
      "    accuracy                           0.75      1735\n",
      "   macro avg       0.75      0.75      0.75      1735\n",
      "weighted avg       0.75      0.75      0.75      1735\n",
      "\n",
      "üß† Training binary model for JP with balanced class weights...\n",
      "JP - Accuracy: 0.6254, F1: 0.6284\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.65      0.68      1048\n",
      "           1       0.52      0.59      0.56       687\n",
      "\n",
      "    accuracy                           0.63      1735\n",
      "   macro avg       0.62      0.62      0.62      1735\n",
      "weighted avg       0.63      0.63      0.63      1735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop over variants\n",
    "for var in variants:\n",
    "    print(f\"\\nüîç Processing variant: {var}\")\n",
    "    \n",
    "    # Prepare train and test texts\n",
    "    print(\"üìù Preparing text features...\")\n",
    "    tqdm.pandas()\n",
    "    train_df['text'] = train_df.progress_apply(\n",
    "        lambda row: prepare_text(row[f'tokens_{var}'], row[f'Bigrams_{var}'], row[f'Trigrams_{var}'], use_ngrams=True), axis=1\n",
    "    )\n",
    "    test_df['text'] = test_df.progress_apply(\n",
    "        lambda row: prepare_text(row[f'tokens_{var}'], row[f'Bigrams_{var}'], row[f'Trigrams_{var}'], use_ngrams=True), axis=1\n",
    "    )\n",
    "    \n",
    "    X_train = train_df['text']\n",
    "    X_test = test_df['text']\n",
    "    \n",
    "    # Multi-class (16 types)\n",
    "    print(\"üß† Training multi-class model with balanced class weights...\")\n",
    "    y_train_multi = train_df['type']\n",
    "    y_test_multi = test_df['type']\n",
    "    \n",
    "    pipeline_multi = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1,3))),\n",
    "        ('clf', LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, class_weight='balanced'))\n",
    "    ])\n",
    "    # params = {'clf__C': [0.1, 1, 10], 'clf__solver': ['lbfgs', 'liblinear']}\n",
    "    # grid = GridSearchCV(pipeline_multi, params, cv=5, scoring='f1_weighted')\n",
    "    # grid.fit(X_train, y_train_multi)\n",
    "    \n",
    "    pipeline_multi.fit(X_train, y_train_multi)\n",
    "    \n",
    "    y_pred_multi = pipeline_multi.predict(X_test)\n",
    "    \n",
    "    acc_multi = accuracy_score(y_test_multi, y_pred_multi)\n",
    "    f1_multi = f1_score(y_test_multi, y_pred_multi, average='weighted')\n",
    "    \n",
    "    results_multi[var] = {'accuracy': acc_multi, 'f1': f1_multi}\n",
    "    print(f\"Multi-class - Accuracy: {acc_multi:.4f}, F1: {f1_multi:.4f}\")\n",
    "    print(classification_report(y_test_multi, y_pred_multi))\n",
    "    \n",
    "    # Save model\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    joblib.dump(pipeline_multi, f'models/multi_{var}.pkl')\n",
    "    \n",
    "    # Binary classifiers for each dimension\n",
    "    for dim in ['IE', 'NS', 'FT', 'JP']:\n",
    "        print(f\"üß† Training binary model for {dim} with balanced class weights...\")\n",
    "        y_train_bin = train_df[dim]\n",
    "        y_test_bin = test_df[dim]\n",
    "        \n",
    "        pipeline_bin = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1,3))),\n",
    "            ('clf', LogisticRegression(solver='lbfgs', max_iter=1000, class_weight='balanced'))\n",
    "        ])\n",
    "        \n",
    "        pipeline_bin.fit(X_train, y_train_bin)\n",
    "        y_pred_bin = pipeline_bin.predict(X_test)\n",
    "        \n",
    "        acc_bin = accuracy_score(y_test_bin, y_pred_bin)\n",
    "        f1_bin = f1_score(y_test_bin, y_pred_bin, average='weighted')\n",
    "        \n",
    "        results_binary[dim][var] = {'accuracy': acc_bin, 'f1': f1_bin}\n",
    "        print(f\"{dim} - Accuracy: {acc_bin:.4f}, F1: {f1_bin:.4f}\")\n",
    "        print(classification_report(y_test_bin, y_pred_bin))\n",
    "        \n",
    "        # Save model\n",
    "        joblib.dump(pipeline_bin, f'models/binary_{dim}_{var}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a24aa196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Comparison of Multi-class Results:\n",
      "without_lemma: Accuracy=0.3527, F1=0.3671\n",
      "with_lemma: Accuracy=0.3470, F1=0.3608\n",
      "with_lemma_pos: Accuracy=0.3412, F1=0.3572\n",
      "with_dep_tree: Accuracy=0.1516, F1=0.1692\n",
      "with_chunking: Accuracy=0.2767, F1=0.2926\n",
      "\n",
      "üìä Comparison of Binary IE Results:\n",
      "without_lemma: Accuracy=0.7308, F1=0.7447\n",
      "with_lemma: Accuracy=0.7297, F1=0.7436\n",
      "with_lemma_pos: Accuracy=0.7222, F1=0.7368\n",
      "with_dep_tree: Accuracy=0.6571, F1=0.6775\n",
      "with_chunking: Accuracy=0.7037, F1=0.7196\n",
      "\n",
      "üìä Comparison of Binary NS Results:\n",
      "without_lemma: Accuracy=0.7856, F1=0.8067\n",
      "with_lemma: Accuracy=0.7844, F1=0.8053\n",
      "with_lemma_pos: Accuracy=0.7850, F1=0.8061\n",
      "with_dep_tree: Accuracy=0.6928, F1=0.7291\n",
      "with_chunking: Accuracy=0.7556, F1=0.7813\n",
      "\n",
      "üìä Comparison of Binary FT Results:\n",
      "without_lemma: Accuracy=0.7821, F1=0.7824\n",
      "with_lemma: Accuracy=0.7879, F1=0.7882\n",
      "with_lemma_pos: Accuracy=0.7775, F1=0.7779\n",
      "with_dep_tree: Accuracy=0.6496, F1=0.6501\n",
      "with_chunking: Accuracy=0.7487, F1=0.7490\n",
      "\n",
      "üìä Comparison of Binary JP Results:\n",
      "without_lemma: Accuracy=0.6663, F1=0.6689\n",
      "with_lemma: Accuracy=0.6692, F1=0.6719\n",
      "with_lemma_pos: Accuracy=0.6622, F1=0.6649\n",
      "with_dep_tree: Accuracy=0.5775, F1=0.5816\n",
      "with_chunking: Accuracy=0.6254, F1=0.6284\n",
      "‚úÖ Training and evaluation complete! Models saved in models/ directory.\n"
     ]
    }
   ],
   "source": [
    "# Compare results\n",
    "print(\"\\nüìä Comparison of Multi-class Results:\")\n",
    "for var, res in results_multi.items():\n",
    "    print(f\"{var}: Accuracy={res['accuracy']:.4f}, F1={res['f1']:.4f}\")\n",
    "\n",
    "for dim in ['IE', 'NS', 'FT', 'JP']:\n",
    "    print(f\"\\nüìä Comparison of Binary {dim} Results:\")\n",
    "    for var, res in results_binary[dim].items():\n",
    "        print(f\"{var}: Accuracy={res['accuracy']:.4f}, F1={res['f1']:.4f}\")\n",
    "\n",
    "print(\"‚úÖ Training and evaluation complete! Models saved in models/ directory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_miniproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
