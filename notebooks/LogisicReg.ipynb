{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce6691dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import List, Tuple\n",
    "import os\n",
    "import joblib\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7692cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading processed data...\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "print(\"üìÇ Loading processed data...\")\n",
    "train_df = pd.read_pickle('../data/processed/train.pkl')\n",
    "test_df = pd.read_pickle('../data/processed/test.pkl')\n",
    "\n",
    "# Variants\n",
    "variants = [\n",
    "    'without_lemma',\n",
    "    'with_lemma',\n",
    "    'with_lemma_pos',\n",
    "    'with_dep_tree',\n",
    "    'with_chunking'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa935ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare text from tokens/ngrams\n",
    "def prepare_text(tokens: List, ngrams_b: List[Tuple], ngrams_t: List[Tuple], use_ngrams: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Convert tokens and optionally ngrams to string for TF-IDF.\n",
    "    For ngrams, join tuples into space-separated strings.\n",
    "    \"\"\"\n",
    "    if not tokens:\n",
    "        return ''\n",
    "    # Handle different token formats (str or tuples)\n",
    "    if isinstance(tokens[0], str):\n",
    "        text = ' '.join(tokens)\n",
    "    elif isinstance(tokens[0], tuple):\n",
    "        text = ' '.join(['_'.join(t) for t in tokens])\n",
    "    else:\n",
    "        text = ''\n",
    "    \n",
    "    if use_ngrams:\n",
    "        bigrams_str = ' '.join(['_'.join(gram) for gram in ngrams_b]) if ngrams_b else ''\n",
    "        trigrams_str = ' '.join(['_'.join(gram) for gram in ngrams_t]) if ngrams_t else ''\n",
    "        text = f\"{text} {bigrams_str} {trigrams_str}\".strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7213cc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results storage\n",
    "results_multi = {}\n",
    "results_binary = {dim: {} for dim in ['IE', 'NS', 'FT', 'JP']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "263a777b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Processing variant: without_lemma\n",
      "üìù Preparing text features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6940/6940 [00:02<00:00, 2337.82it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1735/1735 [00:00<00:00, 3589.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Training multi-class model with balanced class weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mayasalkhateeb/Desktop/HIAST/NLP/Lab/mbti-personality-classifier/nlp_miniproj/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-class - Accuracy: 0.4732, F1: 0.4866\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.24      0.45      0.31        38\n",
      "        ENFP       0.41      0.42      0.41       135\n",
      "        ENTJ       0.22      0.43      0.29        46\n",
      "        ENTP       0.50      0.47      0.49       137\n",
      "        ESFJ       0.33      0.22      0.27         9\n",
      "        ESFP       0.00      0.00      0.00        10\n",
      "        ESTJ       0.20      0.12      0.15         8\n",
      "        ESTP       0.11      0.11      0.11        18\n",
      "        INFJ       0.64      0.41      0.50       294\n",
      "        INFP       0.65      0.55      0.59       366\n",
      "        INTJ       0.52      0.44      0.48       218\n",
      "        INTP       0.60      0.57      0.59       261\n",
      "        ISFJ       0.27      0.42      0.33        33\n",
      "        ISFP       0.23      0.44      0.30        54\n",
      "        ISTJ       0.20      0.32      0.25        41\n",
      "        ISTP       0.39      0.60      0.47        67\n",
      "\n",
      "    accuracy                           0.47      1735\n",
      "   macro avg       0.34      0.37      0.35      1735\n",
      "weighted avg       0.52      0.47      0.49      1735\n",
      "\n",
      "üß† Training binary model for IE with balanced class weights...\n",
      "IE - Accuracy: 0.7833, F1: 0.7917\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.67      0.59       401\n",
      "           1       0.89      0.82      0.85      1334\n",
      "\n",
      "    accuracy                           0.78      1735\n",
      "   macro avg       0.71      0.74      0.72      1735\n",
      "weighted avg       0.81      0.78      0.79      1735\n",
      "\n",
      "üß† Training binary model for NS with balanced class weights...\n",
      "NS - Accuracy: 0.8092, F1: 0.8263\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.61      0.47       240\n",
      "           1       0.93      0.84      0.88      1495\n",
      "\n",
      "    accuracy                           0.81      1735\n",
      "   macro avg       0.66      0.72      0.68      1735\n",
      "weighted avg       0.85      0.81      0.83      1735\n",
      "\n",
      "üß† Training binary model for FT with balanced class weights...\n",
      "FT - Accuracy: 0.8058, F1: 0.8060\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.81      0.79       796\n",
      "           1       0.83      0.80      0.82       939\n",
      "\n",
      "    accuracy                           0.81      1735\n",
      "   macro avg       0.80      0.81      0.81      1735\n",
      "weighted avg       0.81      0.81      0.81      1735\n",
      "\n",
      "üß† Training binary model for JP with balanced class weights...\n",
      "JP - Accuracy: 0.7101, F1: 0.7120\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.75      1048\n",
      "           1       0.62      0.68      0.65       687\n",
      "\n",
      "    accuracy                           0.71      1735\n",
      "   macro avg       0.70      0.71      0.70      1735\n",
      "weighted avg       0.72      0.71      0.71      1735\n",
      "\n",
      "\n",
      "üîç Processing variant: with_lemma\n",
      "üìù Preparing text features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6940/6940 [00:03<00:00, 2209.52it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1735/1735 [00:00<00:00, 2151.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Training multi-class model with balanced class weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mayasalkhateeb/Desktop/HIAST/NLP/Lab/mbti-personality-classifier/nlp_miniproj/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-class - Accuracy: 0.4749, F1: 0.4887\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.23      0.42      0.30        38\n",
      "        ENFP       0.40      0.44      0.42       135\n",
      "        ENTJ       0.24      0.46      0.31        46\n",
      "        ENTP       0.49      0.49      0.49       137\n",
      "        ESFJ       0.29      0.22      0.25         9\n",
      "        ESFP       0.00      0.00      0.00        10\n",
      "        ESTJ       0.25      0.12      0.17         8\n",
      "        ESTP       0.19      0.17      0.18        18\n",
      "        INFJ       0.65      0.41      0.50       294\n",
      "        INFP       0.66      0.57      0.61       366\n",
      "        INTJ       0.53      0.43      0.47       218\n",
      "        INTP       0.61      0.57      0.59       261\n",
      "        ISFJ       0.24      0.36      0.29        33\n",
      "        ISFP       0.21      0.43      0.28        54\n",
      "        ISTJ       0.18      0.27      0.21        41\n",
      "        ISTP       0.40      0.58      0.47        67\n",
      "\n",
      "    accuracy                           0.47      1735\n",
      "   macro avg       0.35      0.37      0.35      1735\n",
      "weighted avg       0.52      0.47      0.49      1735\n",
      "\n",
      "üß† Training binary model for IE with balanced class weights...\n",
      "IE - Accuracy: 0.7741, F1: 0.7832\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.66      0.57       401\n",
      "           1       0.89      0.81      0.85      1334\n",
      "\n",
      "    accuracy                           0.77      1735\n",
      "   macro avg       0.70      0.73      0.71      1735\n",
      "weighted avg       0.80      0.77      0.78      1735\n",
      "\n",
      "üß† Training binary model for NS with balanced class weights...\n",
      "NS - Accuracy: 0.8069, F1: 0.8237\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.59      0.46       240\n",
      "           1       0.93      0.84      0.88      1495\n",
      "\n",
      "    accuracy                           0.81      1735\n",
      "   macro avg       0.65      0.71      0.67      1735\n",
      "weighted avg       0.85      0.81      0.82      1735\n",
      "\n",
      "üß† Training binary model for FT with balanced class weights...\n",
      "FT - Accuracy: 0.8017, F1: 0.8020\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.82      0.79       796\n",
      "           1       0.83      0.79      0.81       939\n",
      "\n",
      "    accuracy                           0.80      1735\n",
      "   macro avg       0.80      0.80      0.80      1735\n",
      "weighted avg       0.80      0.80      0.80      1735\n",
      "\n",
      "üß† Training binary model for JP with balanced class weights...\n",
      "JP - Accuracy: 0.7135, F1: 0.7153\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.73      0.76      1048\n",
      "           1       0.63      0.68      0.65       687\n",
      "\n",
      "    accuracy                           0.71      1735\n",
      "   macro avg       0.70      0.71      0.70      1735\n",
      "weighted avg       0.72      0.71      0.72      1735\n",
      "\n",
      "\n",
      "üîç Processing variant: with_lemma_pos\n",
      "üìù Preparing text features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6940/6940 [00:04<00:00, 1436.53it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1735/1735 [00:01<00:00, 1478.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Training multi-class model with balanced class weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mayasalkhateeb/Desktop/HIAST/NLP/Lab/mbti-personality-classifier/nlp_miniproj/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-class - Accuracy: 0.4703, F1: 0.4820\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.24      0.45      0.31        38\n",
      "        ENFP       0.38      0.42      0.40       135\n",
      "        ENTJ       0.23      0.48      0.31        46\n",
      "        ENTP       0.49      0.45      0.47       137\n",
      "        ESFJ       0.33      0.22      0.27         9\n",
      "        ESFP       0.00      0.00      0.00        10\n",
      "        ESTJ       0.20      0.12      0.15         8\n",
      "        ESTP       0.15      0.11      0.13        18\n",
      "        INFJ       0.64      0.40      0.50       294\n",
      "        INFP       0.63      0.55      0.59       366\n",
      "        INTJ       0.52      0.44      0.48       218\n",
      "        INTP       0.60      0.55      0.57       261\n",
      "        ISFJ       0.27      0.42      0.33        33\n",
      "        ISFP       0.25      0.48      0.33        54\n",
      "        ISTJ       0.19      0.29      0.23        41\n",
      "        ISTP       0.39      0.61      0.47        67\n",
      "\n",
      "    accuracy                           0.47      1735\n",
      "   macro avg       0.35      0.38      0.35      1735\n",
      "weighted avg       0.51      0.47      0.48      1735\n",
      "\n",
      "üß† Training binary model for IE with balanced class weights...\n",
      "IE - Accuracy: 0.7712, F1: 0.7804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.65      0.57       401\n",
      "           1       0.88      0.81      0.84      1334\n",
      "\n",
      "    accuracy                           0.77      1735\n",
      "   macro avg       0.69      0.73      0.71      1735\n",
      "weighted avg       0.80      0.77      0.78      1735\n",
      "\n",
      "üß† Training binary model for NS with balanced class weights...\n",
      "NS - Accuracy: 0.8092, F1: 0.8267\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.62      0.47       240\n",
      "           1       0.93      0.84      0.88      1495\n",
      "\n",
      "    accuracy                           0.81      1735\n",
      "   macro avg       0.66      0.73      0.68      1735\n",
      "weighted avg       0.86      0.81      0.83      1735\n",
      "\n",
      "üß† Training binary model for FT with balanced class weights...\n",
      "FT - Accuracy: 0.8012, F1: 0.8015\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.81      0.79       796\n",
      "           1       0.83      0.79      0.81       939\n",
      "\n",
      "    accuracy                           0.80      1735\n",
      "   macro avg       0.80      0.80      0.80      1735\n",
      "weighted avg       0.80      0.80      0.80      1735\n",
      "\n",
      "üß† Training binary model for JP with balanced class weights...\n",
      "JP - Accuracy: 0.7147, F1: 0.7160\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.74      0.76      1048\n",
      "           1       0.63      0.67      0.65       687\n",
      "\n",
      "    accuracy                           0.71      1735\n",
      "   macro avg       0.70      0.71      0.70      1735\n",
      "weighted avg       0.72      0.71      0.72      1735\n",
      "\n",
      "\n",
      "üîç Processing variant: with_dep_tree\n",
      "üìù Preparing text features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6940/6940 [00:03<00:00, 2216.17it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1735/1735 [00:01<00:00, 1723.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Training multi-class model with balanced class weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mayasalkhateeb/Desktop/HIAST/NLP/Lab/mbti-personality-classifier/nlp_miniproj/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-class - Accuracy: 0.3585, F1: 0.3836\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.18      0.47      0.26        38\n",
      "        ENFP       0.37      0.36      0.36       135\n",
      "        ENTJ       0.12      0.37      0.18        46\n",
      "        ENTP       0.43      0.36      0.39       137\n",
      "        ESFJ       0.14      0.22      0.17         9\n",
      "        ESFP       0.00      0.00      0.00        10\n",
      "        ESTJ       0.17      0.12      0.14         8\n",
      "        ESTP       0.05      0.11      0.07        18\n",
      "        INFJ       0.58      0.32      0.41       294\n",
      "        INFP       0.63      0.42      0.50       366\n",
      "        INTJ       0.41      0.27      0.32       218\n",
      "        INTP       0.49      0.42      0.45       261\n",
      "        ISFJ       0.14      0.30      0.19        33\n",
      "        ISFP       0.17      0.35      0.23        54\n",
      "        ISTJ       0.13      0.27      0.17        41\n",
      "        ISTP       0.26      0.43      0.32        67\n",
      "\n",
      "    accuracy                           0.36      1735\n",
      "   macro avg       0.27      0.30      0.26      1735\n",
      "weighted avg       0.45      0.36      0.38      1735\n",
      "\n",
      "üß† Training binary model for IE with balanced class weights...\n",
      "IE - Accuracy: 0.7366, F1: 0.7508\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.65      0.53       401\n",
      "           1       0.88      0.76      0.82      1334\n",
      "\n",
      "    accuracy                           0.74      1735\n",
      "   macro avg       0.66      0.70      0.67      1735\n",
      "weighted avg       0.78      0.74      0.75      1735\n",
      "\n",
      "üß† Training binary model for NS with balanced class weights...\n",
      "NS - Accuracy: 0.7810, F1: 0.8040\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.59      0.43       240\n",
      "           1       0.92      0.81      0.86      1495\n",
      "\n",
      "    accuracy                           0.78      1735\n",
      "   macro avg       0.63      0.70      0.65      1735\n",
      "weighted avg       0.84      0.78      0.80      1735\n",
      "\n",
      "üß† Training binary model for FT with balanced class weights...\n",
      "FT - Accuracy: 0.7741, F1: 0.7744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.79      0.76       796\n",
      "           1       0.81      0.76      0.78       939\n",
      "\n",
      "    accuracy                           0.77      1735\n",
      "   macro avg       0.77      0.78      0.77      1735\n",
      "weighted avg       0.78      0.77      0.77      1735\n",
      "\n",
      "üß† Training binary model for JP with balanced class weights...\n",
      "JP - Accuracy: 0.6744, F1: 0.6772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.68      0.72      1048\n",
      "           1       0.58      0.66      0.62       687\n",
      "\n",
      "    accuracy                           0.67      1735\n",
      "   macro avg       0.67      0.67      0.67      1735\n",
      "weighted avg       0.68      0.67      0.68      1735\n",
      "\n",
      "\n",
      "üîç Processing variant: with_chunking\n",
      "üìù Preparing text features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6940/6940 [00:03<00:00, 1962.59it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1735/1735 [00:00<00:00, 1760.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Training multi-class model with balanced class weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mayasalkhateeb/Desktop/HIAST/NLP/Lab/mbti-personality-classifier/nlp_miniproj/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-class - Accuracy: 0.3804, F1: 0.3979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ENFJ       0.17      0.42      0.25        38\n",
      "        ENFP       0.30      0.30      0.30       135\n",
      "        ENTJ       0.15      0.37      0.21        46\n",
      "        ENTP       0.40      0.37      0.39       137\n",
      "        ESFJ       0.17      0.33      0.22         9\n",
      "        ESFP       0.00      0.00      0.00        10\n",
      "        ESTJ       0.50      0.25      0.33         8\n",
      "        ESTP       0.10      0.17      0.12        18\n",
      "        INFJ       0.54      0.31      0.39       294\n",
      "        INFP       0.59      0.41      0.48       366\n",
      "        INTJ       0.45      0.37      0.41       218\n",
      "        INTP       0.53      0.48      0.50       261\n",
      "        ISFJ       0.19      0.39      0.26        33\n",
      "        ISFP       0.20      0.43      0.27        54\n",
      "        ISTJ       0.20      0.29      0.24        41\n",
      "        ISTP       0.33      0.48      0.39        67\n",
      "\n",
      "    accuracy                           0.38      1735\n",
      "   macro avg       0.30      0.34      0.30      1735\n",
      "weighted avg       0.45      0.38      0.40      1735\n",
      "\n",
      "üß† Training binary model for IE with balanced class weights...\n",
      "IE - Accuracy: 0.7280, F1: 0.7412\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.60      0.50       401\n",
      "           1       0.86      0.77      0.81      1334\n",
      "\n",
      "    accuracy                           0.73      1735\n",
      "   macro avg       0.65      0.68      0.66      1735\n",
      "weighted avg       0.76      0.73      0.74      1735\n",
      "\n",
      "üß† Training binary model for NS with balanced class weights...\n",
      "NS - Accuracy: 0.7793, F1: 0.8010\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.55      0.41       240\n",
      "           1       0.92      0.82      0.86      1495\n",
      "\n",
      "    accuracy                           0.78      1735\n",
      "   macro avg       0.62      0.68      0.64      1735\n",
      "weighted avg       0.84      0.78      0.80      1735\n",
      "\n",
      "üß† Training binary model for FT with balanced class weights...\n",
      "FT - Accuracy: 0.7700, F1: 0.7704\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76       796\n",
      "           1       0.81      0.75      0.78       939\n",
      "\n",
      "    accuracy                           0.77      1735\n",
      "   macro avg       0.77      0.77      0.77      1735\n",
      "weighted avg       0.77      0.77      0.77      1735\n",
      "\n",
      "üß† Training binary model for JP with balanced class weights...\n",
      "JP - Accuracy: 0.6795, F1: 0.6820\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.70      0.72      1048\n",
      "           1       0.59      0.65      0.62       687\n",
      "\n",
      "    accuracy                           0.68      1735\n",
      "   macro avg       0.67      0.67      0.67      1735\n",
      "weighted avg       0.69      0.68      0.68      1735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop over variants\n",
    "for var in variants:\n",
    "    print(f\"\\nüîç Processing variant: {var}\")\n",
    "    \n",
    "    # Prepare train and test texts\n",
    "    print(\"üìù Preparing text features...\")\n",
    "    tqdm.pandas()\n",
    "    train_df['text'] = train_df.progress_apply(\n",
    "        lambda row: prepare_text(row[f'tokens_{var}'], row[f'Bigrams_{var}'], row[f'Trigrams_{var}'], use_ngrams=True), axis=1\n",
    "    )\n",
    "    test_df['text'] = test_df.progress_apply(\n",
    "        lambda row: prepare_text(row[f'tokens_{var}'], row[f'Bigrams_{var}'], row[f'Trigrams_{var}'], use_ngrams=True), axis=1\n",
    "    )\n",
    "    \n",
    "    X_train = train_df['text']\n",
    "    X_test = test_df['text']\n",
    "    \n",
    "    # Multi-class (16 types)\n",
    "    print(\"üß† Training multi-class model with balanced class weights...\")\n",
    "    y_train_multi = train_df['type']\n",
    "    y_test_multi = test_df['type']\n",
    "    \n",
    "    pipeline_multi = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1,3))),\n",
    "        ('clf', LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, class_weight='balanced'))\n",
    "    ])\n",
    "    \n",
    "    pipeline_multi.fit(X_train, y_train_multi)\n",
    "    y_pred_multi = pipeline_multi.predict(X_test)\n",
    "    \n",
    "    acc_multi = accuracy_score(y_test_multi, y_pred_multi)\n",
    "    f1_multi = f1_score(y_test_multi, y_pred_multi, average='weighted')\n",
    "    \n",
    "    results_multi[var] = {'accuracy': acc_multi, 'f1': f1_multi}\n",
    "    print(f\"Multi-class - Accuracy: {acc_multi:.4f}, F1: {f1_multi:.4f}\")\n",
    "    print(classification_report(y_test_multi, y_pred_multi))\n",
    "    \n",
    "    # Save model\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    joblib.dump(pipeline_multi, f'models/multi_{var}.pkl')\n",
    "    \n",
    "    # Binary classifiers for each dimension\n",
    "    for dim in ['IE', 'NS', 'FT', 'JP']:\n",
    "        print(f\"üß† Training binary model for {dim} with balanced class weights...\")\n",
    "        y_train_bin = train_df[dim]\n",
    "        y_test_bin = test_df[dim]\n",
    "        \n",
    "        pipeline_bin = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1,3))),\n",
    "            ('clf', LogisticRegression(solver='lbfgs', max_iter=1000, class_weight='balanced'))\n",
    "        ])\n",
    "        \n",
    "        pipeline_bin.fit(X_train, y_train_bin)\n",
    "        y_pred_bin = pipeline_bin.predict(X_test)\n",
    "        \n",
    "        acc_bin = accuracy_score(y_test_bin, y_pred_bin)\n",
    "        f1_bin = f1_score(y_test_bin, y_pred_bin, average='weighted')\n",
    "        \n",
    "        results_binary[dim][var] = {'accuracy': acc_bin, 'f1': f1_bin}\n",
    "        print(f\"{dim} - Accuracy: {acc_bin:.4f}, F1: {f1_bin:.4f}\")\n",
    "        print(classification_report(y_test_bin, y_pred_bin))\n",
    "        \n",
    "        # Save model\n",
    "        joblib.dump(pipeline_bin, f'models/binary_{dim}_{var}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a24aa196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Comparison of Multi-class Results:\n",
      "without_lemma: Accuracy=0.4732, F1=0.4866\n",
      "with_lemma: Accuracy=0.4749, F1=0.4887\n",
      "with_lemma_pos: Accuracy=0.4703, F1=0.4820\n",
      "with_dep_tree: Accuracy=0.3585, F1=0.3836\n",
      "with_chunking: Accuracy=0.3804, F1=0.3979\n",
      "\n",
      "üìä Comparison of Binary IE Results:\n",
      "without_lemma: Accuracy=0.7833, F1=0.7917\n",
      "with_lemma: Accuracy=0.7741, F1=0.7832\n",
      "with_lemma_pos: Accuracy=0.7712, F1=0.7804\n",
      "with_dep_tree: Accuracy=0.7366, F1=0.7508\n",
      "with_chunking: Accuracy=0.7280, F1=0.7412\n",
      "\n",
      "üìä Comparison of Binary NS Results:\n",
      "without_lemma: Accuracy=0.8092, F1=0.8263\n",
      "with_lemma: Accuracy=0.8069, F1=0.8237\n",
      "with_lemma_pos: Accuracy=0.8092, F1=0.8267\n",
      "with_dep_tree: Accuracy=0.7810, F1=0.8040\n",
      "with_chunking: Accuracy=0.7793, F1=0.8010\n",
      "\n",
      "üìä Comparison of Binary FT Results:\n",
      "without_lemma: Accuracy=0.8058, F1=0.8060\n",
      "with_lemma: Accuracy=0.8017, F1=0.8020\n",
      "with_lemma_pos: Accuracy=0.8012, F1=0.8015\n",
      "with_dep_tree: Accuracy=0.7741, F1=0.7744\n",
      "with_chunking: Accuracy=0.7700, F1=0.7704\n",
      "\n",
      "üìä Comparison of Binary JP Results:\n",
      "without_lemma: Accuracy=0.7101, F1=0.7120\n",
      "with_lemma: Accuracy=0.7135, F1=0.7153\n",
      "with_lemma_pos: Accuracy=0.7147, F1=0.7160\n",
      "with_dep_tree: Accuracy=0.6744, F1=0.6772\n",
      "with_chunking: Accuracy=0.6795, F1=0.6820\n",
      "‚úÖ Training and evaluation complete! Models saved in models/ directory.\n"
     ]
    }
   ],
   "source": [
    "# Compare results\n",
    "print(\"\\nüìä Comparison of Multi-class Results:\")\n",
    "for var, res in results_multi.items():\n",
    "    print(f\"{var}: Accuracy={res['accuracy']:.4f}, F1={res['f1']:.4f}\")\n",
    "\n",
    "for dim in ['IE', 'NS', 'FT', 'JP']:\n",
    "    print(f\"\\nüìä Comparison of Binary {dim} Results:\")\n",
    "    for var, res in results_binary[dim].items():\n",
    "        print(f\"{var}: Accuracy={res['accuracy']:.4f}, F1={res['f1']:.4f}\")\n",
    "\n",
    "print(\"‚úÖ Training and evaluation complete! Models saved in models/ directory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_miniproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
